Representation Similarity Analysis

for Efﬁcient Task taxonomy & Transfer Learning

Kshitij Dwivedi

Gemma Roig

Singapore University of Technology and Design

kshitij dwivedi@mymail.sutd.edu.sg, gemma roig@sutd.edu.sg

Abstract

Transfer learning is widely used in deep neural network
models when there are few labeled examples available. The
common approach is to take a pre-trained network in a sim-
ilar task and ﬁnetune the model parameters. This is usu-
ally done blindly without a pre-selection from a set of pre-
trained models, or by ﬁnetuning a set of models trained
on different tasks and selecting the best performing one
by cross-validation. We address this problem by propos-
ing an approach to assess the relationship between visual
tasks and their task-speciﬁc models. Our method uses Rep-
resentation Similarity Analysis (RSA), which is commonly
used to ﬁnd a correlation between neuronal responses from
brain data and models. With RSA we obtain a similar-
ity score among tasks by computing correlations between
models trained on different tasks. Our method is efﬁcient
as it requires only pre-trained models, and a few images
with no further training. We demonstrate the effectiveness
and efﬁciency of our method for generating task taxonomy
on Taskonomy dataset. We next evaluate the relationship
of RSA with the transfer learning performance on Taskon-
omy tasks and a new task: Pascal VOC semantic segmen-
tation. Our results reveal that models trained on tasks with
higher similarity score show higher transfer learning per-
formance. Surprisingly, the best transfer learning result for
Pascal VOC semantic segmentation is not obtained from the
pre-trained model on semantic segmentation, probably due
to the domain differences, and our method successfully se-
lects the high performing models.

1. Introduction

For an artiﬁcial agent to perform multiple tasks and learn
in a life-long manner, it should be able to re-utilize infor-
mation acquired in previously learned tasks and transfer it
to learn new tasks from a few examples. A solution to the
aforementioned setting is to use transfer learning. Transfer
learning allows to leverage representations learned from one

Figure 1. Aims of this paper: a) Deploy a strategy for model
selection in transfer learning by b) Finding relationship between
visual tasks.

task to facilitate learning of other tasks, even when labeled
data is expensive or difﬁcult to obtain. [30, 3, 23, 10].

With the recent success of deep neural networks (DNN),
these have become the ipso facto models for almost all vi-
sual tasks [20, 32, 14, 35, 13, 34]. The deployment of
DNN has become possible mostly due to a large amount
of available labeled data, as well as advances in comput-
ing resources [20, 32, 14]. The need for data is a limita-
tion that researchers have overcome by introducing transfer
learning techniques. Transfer learning in DNN commonly
consists of taking a pre-trained model in a similar task or

12387

a)b)domain, and ﬁnetune the parameters to the new task. For
instance, [30, 10] used a pre-trained model on ImageNet
and ﬁnetuned it for object detection on Pascal VOC.

With a large number of pre-trained models (Figure 1a)
available, trained on a variety of vision tasks, it is not trivial
how to select a pre-trained representation suitable for trans-
fer learning. To devise a model selection strategy, it is cru-
cial to understand the underlying structure and relationship
between tasks (Figure 1b). If the relationship between dif-
ferent tasks is known, the model selection can be performed
by evaluating similarity rankings of different tasks with a
new task, using available pre-trained models.

In a recent work, [34] modeled the relationship between
tasks with a fully computational approach. They also in-
troduce a dataset called Taskonomy, which contains labels
of different visual tasks, ranging from object classiﬁcation
to edge occlusions detection. In this paper, we use the term
Taskonomy for both the approach and the dataset from [34].
Taskonomy approach successfully computes the rela-
tionship between tasks. Yet, the relationship between a
new task with an existing set of tasks is calculated with the
transfer learning performance, which is tedious and com-
putationally expensive. The performance on the new task
is referred to transfer learning performance. To obtain the
relationship of all previous tasks with the new task, Taskon-
omy approach also needs to compute the transfer learning
performance on all the previous tasks using a model trained
on the new task as a source. This defeats the purpose of not
training a model from scratch for the new task, and all the
procedure is computationally demanding as it is repeated
for all the existing set of speciﬁc-task models. In this work,
we address the above limitations by providing an alternative
method to ﬁnd the relationship between tasks.

We propose a novel approach to obtain task relationships
using representation similarity analysis (RSA). In compu-
tational neuroscience, RSA is widely used as a tool to
compare brain responses with computational and behav-
ioral models. Motivated by the success of RSA in neuro-
science [18, 4, 16, 1, 5, 25, 11], we investigate the applica-
tion of RSA in obtaining task similarities (Figure 1b) and in
transfer learning (Figure 1a). Our approach relies on the as-
sumption that the representations of the models that perform
a related task will be more similar as compared to tasks that
are not related, which we validate in our analysis.

In our approach, we compute the similarity scores us-
ing pre-trained task-speciﬁc models and a few examples.
Thus, our RSA method only requires the representations of
a few randomly selected images for all the tasks to compute
the similarity, and we do not need to obtain transfer learn-
ing performance by ﬁnetuning on previous tasks’ models.
Further, we show in our results on Taskonomy dataset that
task ranking similarity is independent of model size. Us-
ing small models trained with few samples for the existing

tasks show similar results as the high performing models
trained with all images. This allows to save computational
time and memory, as well as it is more scalable to new tasks
compared to Taskonomy approach.

We ﬁrst validate the transfer learning applicability of our
method on Taskonomy dataset. We ﬁnd that for 16 out
17 Taskonomy tasks, the best model selected using RSA
is in top-5 according to transfer learning performance. We
also report results on Pascal VOC semantic segmentation
task by analyzing the relationship of RSA similarity scores
and the transfer learning performance. Our results show a
strong relationship between RSA similarity score and trans-
fer learning performance. We note that semantic segmen-
tation model from Taskonomy dataset showed a lower sim-
ilarity score than most of the 3D and semantic tasks, and
a similar trend was observed in transfer learning perfor-
mance. Our results suggest that in domain-shift, a model
trained on the same task may not be the best option for
transfer learning, and using our similarity score one can ﬁnd
a better model to achieve better performance. Using our
RSA similarity scores method, we can select models with
better transfer learning performance.

2. Related Works

Here, we discuss the works that are most closely related
to the aim of this paper, namely transfer learning in DNNs
and Taskonomy. Then, we brieﬂy introduce the computa-
tional neuroscience literature that motivated our work.

2.1. Transfer Learning

The usual transfer learning approach in deep neural net-
works (DNNs) is to take a model pre-trained on a large
dataset with annotations as an initialization of a part of
the model. Then, some or all of the parameters are ﬁne-
tuned with backpropagation for a new task. The ﬁnetun-
ing is performed because for most of the tasks there are in-
sufﬁcient annotations to train a DNN from scratch, which
would lead to overﬁtting. Most of the works in the litera-
ture generally initialize the model parameters from a model
pre-trained on Imagenet [6] dataset for image classiﬁca-
tion [20, 32, 14, 31, 22]. For example, [30] use Imagenet
initialized models for object detection on Pascal VOC, [23]
use Imagenet initialized models for semantic segmentation.

It has been noted in multiple works [24, 33, 28], that
the initialization plays a signiﬁcant role in performance in
transfer learning. Hence, a strategy is required to select
models for initialization. Our proposed similarity-based
ranking approach offers a solution to this problem, and as
we discuss in the rest of the paper, tackles the limitations
from Taskonomy [34], which is one of the ﬁrst attempts to
tackle the model selection for transfer learning in DNN.

12388

2.2. Taskonomy

Our work is most closely related to Taskonomy [34],
where the aim is to ﬁnd the underlying task structure
by computing the transfer performance among tasks. To
achieve this goal, they create a dataset of indoor scene im-
ages with annotations available for 26 vision tasks. The
task set, which they refer as task dictionary, covers com-
mon 2D, 3D, and semantics computer vision tasks. Then,
task-speciﬁc independent models are trained in a fully su-
pervised manner for each task in the task dictionary. They
obtain a task similarity score by comparing the transfer
learning performance from each of the task-speciﬁc models
and computing an afﬁnity matrix using a function of trans-
fer learning performance.
In this paper, instead of trans-
fer learning performance, we rely on the similarity of the
feature maps of the pre-trained models. Thus, we avoid
additional training on pre-trained models to obtain transfer
learning performance, saving computational time and mem-
ory, and still obtaining a meaningful relation with transfer
learning performance as we will see in the results section.

2.3. Similarity of computational models and brain

responses

In computational neuroscience, representation similarity
analysis (RSA) is widely used to compare a computational
or behavioral model with the brain responses. In [18], RSA
is used to compute similarities between brain responses in
different regions of visual cortex with categorical models
and computational vision models. In [16], the authors use
several unsupervised and supervised vision models to show
that supervised models explain IT cortical area better than
unsupervised models, and [25] uses RSA to correlate the
dynamics of the visual system with deep neural networks.
We note that as the approach can be used to assess the sim-
ilarity between a computational model and brain data, the
approach can also be utilized to assess similarities between
two computational models. RSA has been rarely used in the
pure computational domain. Only in [26] the RSA was in-
troduced as a loss function for knowledge distillation [15],
and in [27], the consistency of RSA correlations with dif-
ferent random initialization seeds within the same model
trained on CIFAR-10 [19] dataset is explored. However,
RSA is still unexplored in comparing DNNs for assessing
similarity among them. Our work introduces, for the ﬁrst
time, the use of RSA as a similarity measure to ﬁnd the
relationship between tasks, and we believe it opens a new
research line for the deep learning and computer vision.

We use RSA similarity measure for two applications
namely task taxonomy and transfer learning. Our approach
is not limited to only these two applications and can be
further applied in other computer vision problems. For in-
stance, in multi-task learning [17, 13, 7, 21, 8] RSA could
be used for deciding different branching out locations for

Figure 2. Representation Similarity Analysis (RSA): a) Repre-
sentation dissimilarity matrices (RDMs) are generated by comput-
ing the pairwise dissimilarity (1 - Pearson’s correlation) of each
image pair in a subset of selected images. b) Similarity score:
Spearman’s correlation (rs) (denoted with •) of the low triangu-
lar RDMs of the two models is used as the similarity score. Here
DNN1 and DNN2 refer to the models trained on task 1 and 2 re-
spectively.

different tasks, depending on their similarity with the repre-
sentations at different depth of the shared root.

3. Representation Similarity Analysis (RSA)

Representation Similarity Analysis (RSA) [18], illus-
trated in Figure 2, is a widely used data-analytical frame-
work in the ﬁeld of computational neuroscience to quanti-
tatively relate the brain activity measurement with compu-
tational and behavioral models. In RSA, a computational
model and brain activity measurements are related by com-
paring representation-activity dissimilarity matrices. The
dissimilarity matrices are obtained by comparing the pair-
wise dissimilarity of activity/representation associated with
each pair of conditions.

In this work, we introduce RSA as a tool to quantify the
relationship between DNNs and its application in transfer
learning for model selection. We explain the steps to obtain
the dissimilarity matrix for a computational model such as
DNN in the following paragraph.

12389

Representation Dissimilarity Matrix (RDM) We ﬁrst
select a subset of images as conditions for dissimilarity
computation. For a given DNN, we then obtain the rep-
resentation of each image by performing a forward pass
through the model. For each pair of conditions (images),
we compute a dissimilarity score 1 − ρ, where ρ is the Pear-
son’s correlation coefﬁcient. The RDM for this subset of
conditions is then populated by the dissimilarity scores for
each pair of conditions, see Figure 2a.

In our method, the RDMs computed for DNNs are used
for obtaining the similarity between two computer vision
tasks. Note that by using RDMs, the representation for
different tasks can be of different length. The similarity
is computed with the Spearman’s correlation (rs) between
the upper or lower triangular part of the RDMs of the two
DNNs. This is: rs = 1 −
−1) , where di is the differ-
ence between the ranks of ith elements of the lower triangu-
lar part of the two RDMs in Figure 2b, and n are the number
of elements in the lower triangular part of the RDM.

6 P d2
n(n2

i

The Spearman’s correlation provides a quantitative mea-
sure of similarity between the task the DNNs were opti-
mized for (Figure 2b). We explore the application of this
similarity score in obtaining the relationship between com-
puter vision tasks [34], and in transfer learning.

4. RSA for Task Taxonomy and

Transfer Learning

In this section, we introduce our RSA approach for get-
ting a task taxonomy of computer vision tasks, as well as
its application in transfer learning. We show the effec-
tiveness of RSA for obtaining task similarity by answering
three questions: 1) we investigate if we can group tasks into
meaningful clusters based on task type using RSA on pre-
trained task-speciﬁc models; 2) we analyze if the perfor-
mance is important for computing task similarity or we can
use a smaller subset of data with smaller suboptimal mod-
els; and 3) we investigate if the similarity we obtain using
RSA is related to transfer learning.

4.1. Is task similarity related to task type?

We validate our hypothesis that tasks similar according
to RSA are grouped into clusters according to task type,
for instance, 2D, 3D, semantic. To do so, we randomly se-
lect 500 images from the Taskonomy dataset, and select 201
tasks from the task dictionary. Then, we compute the RDMs
of the pre-trained models for each of the 20 tasks using the
task-speciﬁc representations of the 500 sampled images, as
described in section 3. The task-speciﬁc representations are
obtained by doing a forward pass on the pre-trained task-
speciﬁc DNN models. With the resulting RDMs per task,
we compute a pairwise correlation of RDMs of each task

1we exclude Jigsaw task as it is unrelated to all other tasks

with the 19 other tasks to get a 20 × 20 task similarity ma-
trix (Figure 3a). We perform a hierarchical clustering from
the similarity matrix, to visualize if the clustering groups the
tasks according to the task type or some other criteria. We
report the results in the experiments section and compare it
with the clustering obtained with the Taskonomy approach.
We note that RSA is symmetric, as compared to the
transfer performance based metric in Taskonomy [34]. Yet,
symmetry does not affect task similarity rankings, as the po-
sitions of the tasks in the rankings are computed by relative
comparison, and therefore, independent of symmetry.

4.2. Does ranking using RSA depends on dataset

and model size?

We analyze whether RSA based task similarity depends
on the model size and amount of training data. Intuitively,
it should be independent of model and dataset size, because
our method is based on relative similarities. To investi-
gate this, we select a subset of Taskonomy tasks (details
in supp. material section S1) and trained smaller models,
one per task, with fewer parameters than the models pro-
vided by Taskonomy, and on a small subset of Taskonomy
data. First, we evaluate if we obtain a similar task clus-
tering using the small models on the selected tasks. Then,
for each small model, we compute the similarity score
with the pre-trained Taskonomy models on all 20 tasks.
The same analysis is repeated with pre-trained Taskonomy
model trained on the same task, and we compare the relative
similarity based rankings of the small and Taskonomy high-
performing models. If the relative rankings of both small
and Taskonomy model are similar, then the result suggests
that for a completely new task one can train a small model
and compute similarity scores to rank them.

4.3. Is RSA related to transfer performance?

We investigate if RSA based task similarity can be
applied to transfer learning problem. We ﬁrst compute
the correlation between each column of Taskonomy afﬁn-
ity matrix with RSA matrix after removing the diagonal.
As the Taskonomy afﬁnity matrix is populated by raw
losses/evaluations, it is indicative of transfer learning per-
formance [34]. We next select a task and dataset differ-
ent from Taskonomy and obtained the similarity scores of a
model trained on the new task with Taskonomy pre-trained
models. The pre-trained models were ranked according to
the similarity score. We then use the pre-trained models for
initializing the model and add the last task dependent layers
on top of the initialized model to train on the new task. The
ranking based on the transfer performance is compared with
the ranking based on RSA to evaluate the relation between
transfer performance and RSA. As we will see in the results,
RSA can be used to select the high performing models for
transfer learning.

12390

Figure 3. Our approach: a) RSA of task-speciﬁc pre-trained DNN models (from Taskonomy) to compute a task similarity matrix, b) RSA
of small model (SDNN) trained on small datasets and comparison with Taskonomy pre-trained models. c) RSA of small model (SDNNPV)
trained on new task (Pascal VOC semantic segmentation) with Taskonomy pretrained models.

5. Experimental set-up

We ﬁrst provide the details of datasets used for the exper-
iments, followed by the details of the models’ architecture.

5.1. Datasets
It includes over 4 million indoor im-
Taskonomy dataset
ages from 500 buildings with annotations available for 26
image tasks. 21 of these tasks are single image tasks, and
5 tasks are multi-image tasks. For this work, we select 20
single image task for obtaining task similarities1.

We randomly selected 500 images from the Taskonomy
training dataset as 500 different conditions to perform RSA.
These images are used as input to generate representations
of different task-speciﬁc models to compute the RDMs.

To analyze the dependency of RSA on dataset and model
size used for training, we select one building (Hanson) from
Taskonomy dataset, which contains 12138 images. We di-
vide them into 10048 training and 2090 validation images.

Pascal VOC semantic segmentation To evaluate the ap-
plication of RSA in transfer learning, we select the Pas-
cal VOC [9, 12] dataset for semantic segmentation task. It
has pixelwise annotations for 10, 582 training images,1, 449
validation and 1, 456 test images. We argue that this task is
different from the Taskonomy semantic segmentation as the
images are from a different domain.

5.2. Models

Below, we provide details of the network architectures
of pre-trained Taskonomy models, small models trained for
Taskonomy tasks, and models used for Pascal VOC.

Taskonomy models The Taskonomy models 2 consist of
an encoder and decoder. The encoder for all the tasks is a
Resnet-50 [14] model followed by convolution layer that
compresses the channel dimension of the encoder output
from 2048 to 8. The decoder is task-speciﬁc and varies ac-
cording to the task. For classiﬁcation tasks and tasks where
the output is low dimensional the decoder consists of 2-3
fully connected (FC) layers. For all the other tasks, the
decoder consists of 15 layers (except colorization with 12
layers) consisting of convolution and deconvolution layers.
We select the ﬁnal compressed output of the encoder as
the representation for RSA as in [34]. In Taskonomy ap-
proach, the compressed output of the encoder was used as
an input to transfer function to evaluate the transfer learn-
ing performance. Selecting the compressed output of the
encoder ensures that the architecture for all the task is the
same, and the differences in representation can only arise
due to the task that the model was optimized for, as images
are also the same for all tasks.

We also explore the representation of earlier layers of the
encoder and the task labels as the representation for comput-
ing RSA based similarity score. We perform this analysis
to investigate how task speciﬁcity varies across the depth in
the network and if the task’s labels are enough to understand
the relationship between tasks.

Small models The smaller version of the models follows
a similar style to Taskonomy and consists of an encoder
and decoder. The encoder consists of 4 convolution layer
each with a stride of 2 to generate a ﬁnal feature map with
the dimensions same as that of Taskonomy encoder. For

2publicly available at https://github.com/StanfordVL/taskonomy

12391

6.1. Task similarity using RSA

Figure 4a shows the similarity matrix of the tasks com-
puted using RSA with the compressed encoder output as
the task representation. Recall that we compute the 20 × 20
similarity matrix using RSA with given task-speciﬁc repre-
sentations for all the randomly selected 500 images. To vi-
sualize the relationship between tasks, we applied agglom-
erative hierarchical clusteringto the similarity matrix. The
resulting dendrogram from this clustering is shown in Fig-
ure 4b. We can see that the tasks are clustered following
visual criteria of 2D, 3D, and semantic tasks.

We further investigate the task similarity using RSA at
different depths in the encoder architecture and task la-
bels. Figure 5 shows the task similarity matrix for different
depths of the Resnet-50 encoder, namely blocks 1, 2, 3 and
4. We also compare the similarity matrix computed using
the tasks’ labels. We observe, in Figure 5, that at block 1
all the similarity values are very high implying that at ini-
tial layers representations of most of the tasks are similar
irrespective of the task type. As we go deeper, the similar-
ity score between tasks starts decreasing, and in compressed
encoder output, we can see three dark blocks corresponding
to 2D, 3D, and semantic tasks. The above results further
validate our choice of using compressed encoder output as
the task-speciﬁc representation for assessing the similarity
between tasks. Interestingly, the clustering using task labels
does not group into tasks of the same type, and most of the
similarity scores are low. Instead, the labels clustering fol-
lows the output structure of the labels, independently of the
task type. This is because the labels contain only limited
information about the task, and it depends on the annotator
criteria on how to represent the output.

We next compare our approach with Taskonomy ap-
proach5. We use hierarchical clustering to visually com-
pare the dendrograms obtained using both the methods in
Figure 6. For quantifying the similarity, we compute the
correlation of Taskonomy similarity matrix with RSA sim-
ilarity matrix (ρ = 0.62, rs = 0.65). The results show that
both approaches group the tasks into similar clusters with
few exceptions. Room layout is grouped with the vanish-
ing point in Taskonomy approach and in 3D tasks with our
approach. Denoising is clustered with inpainting and au-
toencoding using our approach, which are related tasks. We
argue that our results are plausible.

6.2. Does model size impact similarity score?

In this experiment, we investigate how the model and
dataset size affect task similarity. We show the results of
similarity rankings for 2 tasks: 2D keypoints and surface

Figure 4. Task similarity using RSA: a) Similarity matrix of the
20 Taskonomy tasks, b) Agglomerative clustering using RDM.

this experiment, we select the tasks which require a fully-
convolution decoder structure and use 4 convolution lay-
ers each followed by an upsampling layer. The models are
trained on Hanson subset of Taskonomy dataset.

Pascal VOC Models We use two types of models for Pas-
cal VOC semantic segmentation task: 1) a small model to
compute similarity score with pre-trained Taskonomy mod-
els; 2) models initialized with pre-trained Taskonomy en-
coders to evaluate transfer learning performance. The small
model consists of an encoder and a decoder. The encoder
consists of 4 convolution layer each with a stride of 2 to gen-
erate a ﬁnal feature map with the dimensions same as that of
Taskonomy encoder. The decoder is an Atrous Spatial Pyra-
mid Pooling (ASPP) [2], which contains convolution layers
that operate in parallel with different dilations. The model
is trained on Pascal VOC training set with learning rate 10-4
for 200, 000 iterations. The encoder representation of the
small model trained on Pascal VOC is then used to compute
similarity with Taskonomy pre-trained models. The mod-
els for evaluating transfer learning performance consists of
an encoder with similar architecture as Taskonomy models
and an ASPP decoder. The encoder part is initialized by the
pre-trained Taskonomy models of the corresponding task.

Implementation and evaluation details We use the pub-
licly available tensorﬂow implementation 3 of deeplabv3 [3]
and modify the code for transfer learning experiments. We
use RSA Matlab toolbox [29] for RSA related analysis4. We
refer to the supplementary material for further details.

6. Results

Here, we present the results of RSA for computing task
similarity and its relation to transfer learning performance.
We follow the same nomenclature of task type as in [34],
and color code 2D, 3D, semantic, and geometric tasks.

3https://github.com/sthalles/deeplab v3
4Code available at https://github.com/kshitijd20/RSA-CVPR19-release

5We show 17 tasks as we had access to only afﬁnity values of these
tasks. For comparison with ﬁgure 13 in [34], please refer to section S2 of
supplementary material

12392

a) Task similarity matrixb) Task similarity treeFigure 5. Task taxonomy using RSA: 1 − 5) Similarity matrix of 20 Taskonomy tasks using features at different depth in the model as
task-speciﬁc representations 6) Similarity matrix of 20 Taskonomy tasks using labels as task-speciﬁc representations.

Figure 6. RSA vs Taskonomy: Clustering comparison.

normals (for other tasks, please see section S1 in supple-
mentary material). We compare the similarity rankings ob-
tained using the small model trained on Hanson subset of
Taskonomy data with the Taskonomy model trained on the
same task. As we visually observe from the comparison
(Figure 7) in both the tasks the ranking look similar. For
all the tasks considered in the above comparison the mean
correlation is high (ρ = 0.84, rs = 0.85).

Figure 7. Task taxonomy using small models: Similarity ranking
of (a) keypoint2d Taskonomy model vs small model. (b) surface
normals Taskonomy model vs small model.

omy model and small model is comparable to previous cor-
relation results. The above results together provide strong
evidence that the model and dataset size do not have much
effect on the similarity score.

6.3. Model selection for transfer learning

We ﬁrst report

the model selection using RSA for
Taskonomy tasks and then on Pascal VOC semantic seg-
mentation task.

Next, we also computed task similarity matrices by com-
paring a small model with small models trained on other
tasks. We ﬁnd that the correlation (ρ = 0.85, rs = 0.88)
between task similarity matrices (Figure S3) using Taskon-

Taskonomy We obtain high mean correlation (ρ = 0.70,
rs = 0.76) between RSA and transfer learning for 17 tasks
from the Taskonomy dataset. We also report in Table 1 that
for 16 out of 17 tasks, the best model selected by RSA for

12393

block1block2block3block4compressed encoder outputlabelsOursTaskonomy (Zamir et al. 2018)Top-1 Top-3 Top-5
16/17
7/17

14/17

Table 1. Number of tasks for which best model selected for trans-
fer learning using RSA is in top-n models according to transfer
performance for 17 tasks

transfer learning is in top-5 models selected using Taskon-
omy approach (transfer learning performance).

Pascal VOC We show the relation of similarity score us-
ing RSA with transfer learning by selecting a new task
(semantic segmentation in Pascal VOC). We compare the
transfer learning performance of models initialized by dif-
ferent task-speciﬁc pre-trained models from Taskonomy
dataset. Then we compare the transfer learning perfor-
mance based ranking with similarity score ranking. Here we
select the small Pascal model to compute the similarity with
the Taskonomy models. We report the robustness of simi-
larity ranking using RSA with respect to model size, num-
ber of images used for RSA analysis, and different training
stages in supplementary section S3.

We show the similarity score based ranking in Figure 8.
Surprisingly, semantic segmentation model from Taskon-
omy shows a lower similarity score as compared to other
models trained on semantic (scene class, object class) and
3D tasks (occlusion edges, surface normals). Most of the
2D tasks show low similarity scores.

To investigate if similarity scores are related to trans-
fer learning performance we evaluated the models initial-
ized with task-speciﬁc Taskonomy models, ﬁnetuned with
Pascal VOC training set, and compared the performance on
Pascal VOC test set. Table 1 shows the comparison of trans-
fer learning performance for models with initialization from
a set of selected tasks (For a complete comparison refer to
section S3 in the supplementary material). The tasks are
listed in the order of their similarity scores. We note from
the table that the tasks on the top (object class, scene class,
occlusion edges, and semantic segmentation ) shows higher
performance while autoencoder and vanishing point perfor-
mance is even less than model trained from scratch (random
in Table 2). We note that our results are comparable to the
results (64.81%) reported in [3], when they use Resnet-50
trained on Imagenet for initialization. The results provide
evidence that the similarity score obtained using RSA pro-
vide an estimate of the expected transfer performance.

7. Conclusion

We presented an efﬁcient alternative approach to obtain
the similarity between computer vision models trained on
different tasks using their learned representations. Our ap-
proach uses RSA, and it is suitable for obtaining task simi-
larity by just using the pre-trained models without any fur-
ther training, as opposed to the earlier state of the art method

Figure 8. RSA based similarity of scores of pre-trained Taskonomy
models with the small model trained on Pascal VOC.

Initialization(Task)
Object class
Scene class
Occlusion edges
Semantic segmentation
Autoencoder
Vanishing point
Random(Taskonomy encoder)
Random(Small encoder)

mIoU
0.6492
0.6529
0.6496
0.6487
0.5901
0.5891
0.6083
0.4072

Table 2. Transfer learning performance on Pascal VOC test set.

Taskonomy for this problem.

We provided strong evidence that for obtaining the sim-
ilarity, the model and training dataset size does not play a
signiﬁcant role and we can obtain a task similarity relative
ranking using small models as well as state of the art mod-
els with few data samples. This comes with computational
and memory savings.

We also showed the relationship of the task similarity
using RSA with the transfer learning performance and its
applicability. We demonstrated on both, Taskonomy and
Pascal VOC semantic segmentation, that the transfer learn-
ing performance is closely related to the similarity obtained
with RSA. The above results showed that for domain shift
the model trained on the same task might not be the best ﬁt
for transfer learning and our proposed approach can help in
model selection for transfer learning. Our method is appli-
cable to a wide range of potential problems, such as multi-
task models, architecture selection.

Acknowledgements This work was
funded by the
SUTD-MIT IDC grant (IDG31800103). K.D. was also
funded by SUTD Presidents Graduate Fellowship. We
thank Taskonomy authors for the support and the code.

12394

object classscene classdistance3D edgesroom layout2.5d segment3D keypointsnormalsreshadingsemantic segm2D segment2D edgescurvature2D keypointsautoencodingcolorizationdenoisingz-depthinpaintingvanishing pointTask DNNs00.20.40.60.8Correlation CoefficientSimilarity rankings: Taskonomy with pascal model********************semanticgeometrical2D3DReferences

[1] Michael F Bonner and Russell A Epstein. Computational
mechanisms underlying cortical responses to the affordance
properties of visual scenes. PLOS Computational Biology.

[2] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos,
Kevin Murphy, and Alan L Yuille. Deeplab: Semantic image
segmentation with deep convolutional nets, atrous convolu-
tion, and fully connected crfs. IEEE transactions on pattern
analysis and machine intelligence, 40(4):834–848, 2018.

[3] Liang-Chieh Chen, George Papandreou, Florian Schroff, and
Hartwig Adam. Rethinking atrous convolution for seman-
tic image segmentation. arXiv preprint arXiv:1706.05587,
2017.

[4] Radoslaw Martin Cichy, Aditya Khosla, Dimitrios Pantazis,
Antonio Torralba, and Aude Oliva. Comparison of deep
neural networks to spatio-temporal cortical dynamics of hu-
man visual object recognition reveals hierarchical correspon-
dence. Scientiﬁc Reports, 6(June):1–13, 2016.

[5] Radoslaw Martin Cichy, Dimitrios Pantazis, and Aude Oliva.
Resolving human object recognition in space and time. Na-
ture neuroscience, 17(3):455, 2014.

[6] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,
and Li Fei-Fei.
Imagenet: A large-scale hierarchical im-
age database. In Computer Vision and Pattern Recognition,
2009. CVPR 2009. IEEE Conference on, pages 248–255.
IEEE, 2009.

[7] Thanuja Dharmasiri, Andrew Spek, and Tom Drummond.
Joint prediction of depths, normals and surface curvature
from rgb images using cnns. In Intelligent Robots and Sys-
tems (IROS), 2017 IEEE/RSJ International Conference on,
pages 1505–1512. IEEE, 2017.

[8] Nikita Dvornik, Konstantin Shmelkov, Julien Mairal, and
Cordelia Schmid. Blitznet: A real-time deep network for
scene understanding.

[9] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and
A. Zisserman. The pascal visual object classes (voc) chal-
lenge. International Journal of Computer Vision, 88(2):303–
338, June 2010.

[10] Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra
Malik. Rich feature hierarchies for accurate object detection
and semantic segmentation. In Computer Vision and Pattern
Recognition, 2014.

[11] Iris IA Groen, Michelle R Greene, Christopher Baldassano,
Li Fei-Fei, Diane M Beck, and Chris I Baker. Distinct con-
tributions of functional and deep neural network features to
representational similarity of scenes in human brain and be-
havior. Elife, 7:e32962, 2018.

[12] Bharath Hariharan, Pablo Arbel´aez, Lubomir Bourdev,
Subhransu Maji, and Jitendra Malik. Semantic contours from
inverse detectors.
In Computer Vision (ICCV), 2011 IEEE
International Conference on, pages 991–998. IEEE, 2011.

[13] Kaiming He, Georgia Gkioxari, Piotr Doll´ar, and Ross Gir-
shick. Mask r-cnn. In Computer Vision (ICCV), 2017 IEEE
International Conference on, pages 2980–2988. IEEE, 2017.

ings of the IEEE conference on computer vision and pattern
recognition, pages 770–778, 2016.

[15] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distill-
arXiv preprint

ing the knowledge in a neural network.
arXiv:1503.02531, 2015.

[16] Seyed Mahdi Khaligh-Razavi and Nikolaus Kriegeskorte.
Deep Supervised, but Not Unsupervised, Models May Ex-
plain IT Cortical Representation. PLoS Computational Biol-
ogy, 10(11), 2014.

[17] Iasonas Kokkinos. Ubernet: Training a universal convolu-
tional neural network for low-, mid-, and high-level vision
using diverse datasets and limited memory.

[18] Nikolaus Kriegeskorte, Marieke Mur, and Peter A Ban-
dettini. Representational similarity analysis-connecting the
branches of systems neuroscience. Frontiers in systems neu-
roscience, 2:4, 2008.

[19] Alex Krizhevsky. Learning multiple layers of features from

tiny images. Technical report, Citeseer, 2009.

[20] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
Imagenet classiﬁcation with deep convolutional neural net-
works.
In Advances in neural information processing sys-
tems, pages 1097–1105, 2012.

[21] Bo Li, Chunhua Shen, Yuchao Dai, Anton Van Den Hen-
gel, and Mingyi He. Depth and surface normal estimation
from monocular images using regression on deep features
and hierarchical crfs. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, pages 1119–
1127, 2015.

[22] Fayao Liu, Chunhua Shen, and Guosheng Lin. Deep con-
volutional neural ﬁelds for depth estimation from a single
image. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pages 5162–5170, 2015.

[23] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully
convolutional networks for semantic segmentation. In Pro-
ceedings of the IEEE conference on computer vision and pat-
tern recognition, pages 3431–3440, 2015.

[24] Arun Mallya and Svetlana Lazebnik. Piggyback: Adding
multiple tasks to a single, ﬁxed network by learning to mask.
arXiv preprint arXiv:1801.06519, 2018.

[25] Radoslaw Martin Cichy, Aditya Khosla, Dimitrios Pantazis,
and Aude Oliva. Dynamics of scene representations in the
human brain revealed by magnetoencephalography and deep
neural networks. NeuroImage, 153:346–358, 2017.

[26] Patrick McClure and Nikolaus Kriegeskorte. Representa-
tional distance learning for deep neural networks. Frontiers
in computational neuroscience, 10:131, 2016.

[27] Johannes Mehrer, Nikolaus Kriegeskorte, and Tim Kietz-
mann. Beware of the beginnings: intermediate and higher-
level representations in deep neural networks are strongly af-
fected by weight initialization. In Conference on Cognitive
Computational Neuroscience, 2018.

[28] Mathew Monfort, Bolei Zhou, Sarah Adel Bargal, Tom Yan,
Alex Andonian, Kandan Ramakrishnan, Lisa Brown, Quanfu
Fan, Dan Gutfruend, Carl Vondrick, et al. Moments in time
dataset: one million videos for event understanding.

[14] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In Proceed-

[29] Hamed Nili, Cai Wingﬁeld, Alexander Walther, Li Su,
William Marslen-Wilson, and Nikolaus Kriegeskorte. A

12395

toolbox for representational similarity analysis. PLoS com-
putational biology, 10(4):e1003553, 2014.

[30] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
Faster r-cnn: Towards real-time object detection with region
proposal networks. In Advances in neural information pro-
cessing systems, pages 91–99, 2015.

[31] Karen Simonyan and Andrew Zisserman. Two-stream con-
volutional networks for action recognition in videos. In Ad-
vances in neural information processing systems, pages 568–
576, 2014.

[32] Karen Simonyan and Andrew Zisserman. Very deep convo-
lutional networks for large-scale image recognition. arXiv
preprint arXiv:1409.1556, 2014.

[33] Ilya Sutskever, James Martens, George Dahl, and Geoffrey
Hinton. On the importance of initialization and momentum
in deep learning.
In International conference on machine
learning, pages 1139–1147, 2013.

[34] Amir R Zamir, Alexander Sax, and William Shen. Taskon-

omy: Disentangling task transfer learning.

[35] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang
Wang, and Jiaya Jia. Pyramid scene parsing network.
In
Proceedings of IEEE Conference on Computer Vision and
Pattern Recognition (CVPR), 2017.

12396

