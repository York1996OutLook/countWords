Universal Domain Adaptation

Kaichao You1, Mingsheng Long1(B), Zhangjie Cao1, Jianmin Wang1, and Michael I. Jordan2

1KLiss, MOE; BNRist; School of Software, Tsinghua University, China

1Research Center for Big Data, Tsinghua University, China

1Beijing Key Laboratory for Industrial Big Data System and Application

2University of California, Berkeley, USA

youkaichao@gmail.com, {mingsheng,jimwang}@tsinghua.edu.cn, jordan@cs.berkeley.edu

Abstract

Closed Set DA

Partial DA

Domain adaptation aims to transfer knowledge in the
presence of the domain gap. Existing domain adaptation
methods rely on rich prior knowledge about the relationship
between the label sets of source and target domains, which
greatly limits their application in the wild. This paper intro-
duces Universal Domain Adaptation (UDA) that requires no
prior knowledge on the label sets. For a given source label
set and a target label set, they may contain a common label
set and hold a private label set respectively, bringing up an
additional category gap. UDA requires a model to either (1)
classify the target sample correctly if it is associated with a
label in the common label set, or (2) mark it as “unknown”
otherwise. More importantly, a UDA model should work sta-
bly against a wide spectrum of commonness (the proportion
of the common label set over the complete label set) so that
it can handle real-world problems with unknown target label
sets. To solve the universal domain adaptation problem, we
propose Universal Adaptation Network (UAN). It quantiﬁes
sample-level transferability to discover the common label set
and the label sets private to each domain, thereby promoting
the adaptation in the automatically discovered common label
set and recognizing the “unknown” samples successfully. A
thorough evaluation shows that UAN outperforms the state
of the art closed set, partial and open set domain adaptation
methods in the novel UDA setting.

1. Introduction

Deep learning has boosted the progress of computer vi-
sion and improved state of the art performance on diverse
vision tasks such as image classiﬁcation [13], object detec-
tion [30] and semantic segmentation [12]. However, the
remarkable efﬁcacy of deep learning algorithms highly relies
on abundant labeled training data, which requires tedious
labor work on collecting labeled data. Given a large-scale

Open Set DA (Busto et al. 2017) Open Set DA (Saito et al. 2018)

Universal DA

?

Source Domain Label Set

Target Domain Label Set

Figure 1. Universal Domain Adaptation (UDA) and existing domain
adaptation settings with respect to label sets of source and target
domains (blue shades indicate shared labels). Only UDA is able to
deal with the setting that the label set of target domain is unknown.

unlabeled dataset, it is usually prohibitive to annotate enough
training data such that we can train a deep learning model
that generalizes well. An alternative is to leverage off-the-
shelf labeled data from a related domain (source domain) to
improve the model for the domain of interest (target domain).
The target domain may contain data collected by different
sensors, from different perspectives or under different illumi-
nation conditions compared with the source domain, leading
to large domain gap. Domain adaptation [33] aims to min-
imize the domain gap and successfully transfer the model
trained on the source domain to the target domain.

Existing domain adaptation methods tackle the domain
gap either by learning domain invariant feature representa-
tion, by generating features/samples for target domains or by
transforming samples between domains through generative

2720

models. They suppose that label sets are identical across
domains, as shown in Figure 1 (closed set domain adapta-
tion). This simpliﬁed scenario focuses on the fundamental
problem of domain adaptation and provides insightful ideas
for future research. Recent works try to relax the assumption
by proposing open set domain adaptation [28, 35] and partial
domain adaptation [2, 45]. As shown in Figure 1, partial
domain adaptation [2, 45] requests that the source label set
contains the target label set while Busto et al. [28] introduces
“unknown” classes in both domains, and assumes common
classes between two domains are known in the training phase.
Modiﬁed open set domain adaptation by Saito et al. [35]
removes data of source unknown classes such that the source
label set is a subset of the target label set. Luo et al. [24]
allows partly shared label sets and requires some labeled
data in the target domain, where the target label set is known.
These works constitute valuable advances towards practical
domain adaptation.

Practical scenarios are way more complicated and these
assumptions are easily violated. For example, labeled an-
imals from different datasets are easily accessible. But if
we want to recognize animals in the wild, we are exposed
to two challenges: (1) The background may deviate from
those in the training data, leading to large domain gap; (2)
Some native species do not exist in the training data, in the
meantime, animal species in the deployed environment may
not cover all the training species because training data is too
diverse, leading to large category gap. In summary, the rela-
tionship of label sets between the source and target domains
is unknown in the presence of a large domain gap. If the
source label set is large enough to contain the target label set,
partial domain adaptation methods are good choices; if the
source label set is contained in the target label set or common
classes are known, open set domain adaptation methods are
good choices. In a general scenario, however, we cannot
select the proper domain adaptation method because no prior
knowledge about the target domain label set is given.

For this purpose, we propose a generalized setting, termed
Universal Domain Adaptation (UDA). In UDA, given a
labeled source domain, for any related target domain, regard-
less of how its label set differs from that of the source domain,
we need to classify its samples correctly if it belongs to any
class in the source label set, or mark it as“unknown” other-
wise. The word “universal” indicates that UDA imposes no
prior knowledge on the label sets.

UDA poses two major technical challenges for designing
domain adaptation models in the wild. (1) Since we know
nothing about the target label set, we cannot decide which
part of the source domain should be matched to which part
of the target domain. If we naively match the entire source
domain with the entire target domain, mismatching of dif-
ferent label sets will deteriorate the model. (2) The model
should be able to mark target samples as “unknown” if they

do not belong to any class in the source label set. Since there
are no labeled training data for these classes, by no means
the classiﬁer can tell their detailed category.

To address Universal Domain Adaptation, we propose
Universal Adaptation Network (UAN), equipping with a
novel criterion to quantify the transferability of each sample.
The criterion integrates both the domain similarity and the
prediction uncertainty of each sample into a sample-level
weighting mechanism. With the transferability-enhanced
UAN model, the samples coming from the common label
set between the source and target domains are automatically
detected and matched while the target samples coming from
the target private label set can be successfully marked by a
rejection pipeline as “unknown” class.

The main contributions of this paper are:
(1) We introduce a more practical Universal Domain
Adaptation (UDA) setting that imposes no prior knowledge
on the label sets of source and target domains. This is impor-
tant considering that we do not have access to target labels
in unsupervised domain adaptation and sometimes it is even
impossible to know the target label set, not to mention how
it overlaps with the source label set.

(2) We study the performance of existing domain adap-
tation methods under a variety of UDA settings including
closed set, partial and open set domain adaptation. Methods
tailored to speciﬁc settings do not work well in UDA. This
highlights the need for a UDA-friendly model.

(3) We propose Universal Adaptation Network (UAN), an
end-to-end solution, which exploits both the domain similar-
ity and the prediction uncertainty of each sample to develop
a weighting mechanism for discovering label sets shared by
both domains and promote common-class adaptation. Em-
pirical results show that UAN works stably across different
UDA settings and outperforms existing methods.

2. Related Work

We brieﬂy review recent domain adaptation methods in
this section. According to the constraint on the label set
relationship between domains, these methods fall into closed
set domain adaptation, partial domain adaptation, or open
set domain adaptation.

2.1. Closed Set Domain Adaptation

Closed set domain adaptation focuses on mitigating the
impact of the domain gap between source and target do-
mains. Solutions to closed set domain adaptation mainly fall
into two categories: feature adaptation and generative model.
Feature adaptation methods diminish the feature distribution
discrepancy between source and target domains by minimiz-
ing well-deﬁned statistical distances on feature distributions.
Early shallow adaptation methods [33, 7, 27, 5, 46, 42] usu-
ally provide insights in developing modern deep adaptation
methods [38, 21, 6, 11, 39, 23, 37, 34, 22], while other

2721

deep adaptation methods further explore architecture de-
signs [19, 43, 36, 26, 20, 41, 16, 47, 25, 4, 18]. Tzeng et al.
[38] and Long et al. [21] ﬁrst proposed to minimize Max-
imum Mean Discrepancy (MMD) of deep features across
domains. Long et al. [23] further exploits a residual trans-
fer structure and introduces entropy minimization on target
data. Zellinger et al. [44] enables distribution alignment by
optimizing Central Moment Discrepancy (CMD). Haeusser
et al. [11] constructs a bipartite graph to force feature distri-
bution alignment within clusters. Bhushan et al. [1] enables
domain adaptation by minimizing Earth Mover’s Distance
(EMD) between distributions. Meanwhile, with signiﬁcant
advances made in image synthesis by Generative Adversarial
Nets [8], methods that match feature distributions by gener-
ative models are proposed. They learn a domain classiﬁer
to discriminate features from source and target domains and
force the feature extractor to confuse the domain classiﬁer
in an adversarial learning paradigm [6, 39, 37].

Methods based on generative models synthesize labeled
target samples as data augmentation and match domains in
both pixel and feature levels [19, 36, 16, 20, 26, 17, 41].
With the impressive results of Cycle-Consistent Generative
Adversarial Network [48] in image translation, CycleGAN-
based domain adaptation methods have been studied recently
[15, 32]. These methods usually transform source images
into target-like images and vice versa with CycleGAN, then
train the classiﬁers for each domain respectively with source
images and transformed images.

Attempts for closed set domain adaptation focus on solv-
ing fundamental problems in distribution matching and pro-
vide a solid basis for the extension of domain adaptation.

2.2. Partial Domain Adaptation

The presence of Big Data gives rise to partial domain
adaptation (PDA) [2, 45, 3], which transfers a learner from a
big source domain to a small target domain. The label set of
the source domain is supposed to be large enough to contain
the target label set. To solve partial domain adaptation, Cao
et al. [2] utilizes multiple domain discriminators with class-
level and instance-level weighting mechanism to achieve
per-class adversarial distribution matching. Zhang et al. [45]
constructs an auxiliary domain discriminator to quantify the
probability of a source sample being similar to the target
domain. Cao et al. [3] further improves PDA by employing
only one adversarial network and jointly applying class-level
weighting on the source classiﬁer.

Efforts for partial domain adaptation push well-studied
domain adaptation problem towards a more practical setting.

2.3. Open Set Domain Adaptation

Busto et al. [28] proposed open set domain adaptation
(OSDA), as shown in Figure 1. The classes private to both
domains are uniﬁed as an “unknown” class. They use an

Assign-and-Transform-Iteratively (ATI) algorithm to map
target samples to source classes and then train SVMs for ﬁnal
classiﬁcation. Saito et al. [35] modiﬁed the open set domain
adaptation by requiring no data of the source private label
set and extends the source classiﬁer by adding an explicit
“unknown” class and trains it adversarially among classes.
These methods tackle the domain gap by discarding the
“unknown” classes when common classes are known in ad-
vance. While conﬁned from more generalized settings, they
shed light on designing practical domain adaptation models.

3. Universal Domain Adaptation

In this section, we formally introduce Universal Domain
Adaptation (UDA) setting and address it by a novel Universal
Adaptation Network (UAN).

3.1. Problem Setting

s
i , y

In Universal Domain Adaptation (UDA), a source domain
s
i )} consisting of ns labeled samples and a
Ds = {(x
t
i)} of nt unlabeled samples are
target domain Dt = {(x
provided at training. Note that the source data are sampled
from distribution p while the target data from distribution q.
We use Cs to denote the label set of source domain and Ct the
label set of target domain. C = Cs ∩ Ct is the common label
set shared by both domains. Cs = Cs \ C and Ct = Ct \ C
represent the label sets private to the source domain and the
target domain respectively. pCs and pC are used to denote the
distributions of source data with labels in the label set Cs and
C respectively, and qCt , qC for target distributions with labels
in the label set Ct, C respectively. Note that the target data
are fully unlabeled, and the target label sets (inaccessible at
training) are only used for deﬁning the UDA problem.

We deﬁne the commonness between two domains as the
Jaccard distance of two label sets: ξ = |Cs∩Ct|
|Cs∪Ct| . Closed set
domain adaptation is a special case of UDA when ξ = 1.
The smaller ξ is, the less sharing knowledge is and the more
difﬁcult the adaptation is. The task for UDA is to design a
model that does not know ξ but works well across a wide
spectrum of ξ. It must be able to distinguish between target
data coming from C and target data coming from Ct, as well
as to learn a classiﬁcation model f to minimize the target
risk in the common label set, i.e. min E(x,y)∼qC [f (x) 6= y].

3.2. Technical Challenges

In UDA, a new challenge has emerged, the category gap
between two domains. The root of the category gap lies in
the difference of the label sets. If we naively pick any of
the existing closed set domain adaptation methods to solve
UDA, source data in Cs may be matched with target data
from Ct. Such blind alignment is problematic since their
label sets have no overlap (Cs ∩ Ct = ∅) and forcefully
matching them will cause many target private data to be

2722

Training phase

Testing phase

EG

G

y^

w s,w t

G

y^

argmax y^

No

x

F

z

D'

d'^

ED

x

F

z

w t

w t <w

0?

Yes

unknown

ED'

D

d^

D'

d^

conv layer

fc layer

loss

computation flow

weighting mechanism

Figure 2. The training and testing phases of the Universal Adaptation Network (UAN) designed for Universal Domain Adaptation (UDA).

predicted as a class in Cs whereas they should be marked
as “unknown”. If we turn to tailored methods of partial or
open set domain adaptation, we must face the fact that the
relationship between Cs and Ct is unknown. In the absence
of the conﬁguration about C, Cs and Ct, it is hard to make
a choice among tailored domain adaptation methods. Thus,
we need to automatically identify the source and target data
from C, such that feature alignment can be done in the auto-
discovered common label set.

Despite the category gap, the domain gap still exists in
UDA setting, i.e. between the source and target data in the
common label set. In other words, p 6= q and pC 6= qC.
Domain adaptation should be applied to align distributions
of the source and target data in the common label set C.

Another challenge for UDA is to detect “unknown”
classes. In practice, conﬁdence thresholding, which marks
samples with low classiﬁcation conﬁdence as “unknown”,
is often used. Nonetheless, such a straightforward method
may fail in universal domain adaptation since the predictions
by neural networks are usually overconﬁdent [10] but less
discriminative due to the underlying domain gap.

3.3. Universal Adaptation Network

We propose Universal Adaptation Network (UAN) to ad-
dress the UDA problem. As shown in Figure 2, the architec-
ture of UAN consists of a feature extractor F , an adversarial
domain discriminator D, a non-adversarial domain discrimi-
nator D′ and a label classiﬁer G. Input x from either domain
is fed into the feature extractor F . The extracted feature
z = F (x) is forwarded into the label classiﬁer G to obtain
the probability ˆy = G(z) of x over the source classes Cs.
The non-adversarial domain discriminator D′ obtains the do-
main similarity ˆd′ = D′(z), quantifying the similarity of x
to the source domain. The adversarial domain discriminator

D aims to adversarially match the feature distributions of
the source and target data falling in the common label set C
(Note that we need a mechanism to detect the common label
set). EG, ED′ and ED represent the error for label classiﬁer
G, non-adversarial domain discriminator D′ and adversarial
domain discriminator D, which are formally deﬁned as

EG = E(x,y)∼pL (y, G(F (x)))

ED′ = − Ex∼p log D′ (F (x))

− Ex∼q log (cid:0)1 − D′ (F (x))(cid:1)

ED = − Ex∼pws(x) log D (F (x))

− Ex∼qwt(x) log (1 − D (F (x)))

(1)

(2)

(3)

where L is the standard cross-entropy loss, ws(x) indicates
the probability of a source sample x belonging to the com-
mon label set C, and similarly, wt(x) indicates the probabil-
ity of a target sample x belonging to the common label set
C. The details of ws(x) and wt(x) will be elaborated in the
next subsection. With well-established weighting ws(x) and
wt(x), the adversarial domain discriminator D is conﬁned
to distinguish the source and target data in the common label
set C. Adversarially, the feature extractor F strives to con-
fuse D, yielding domain-invariant features in the common
label set C. The label classiﬁer G trained on such features
can be applied safely to the target domain.

The training of UAN can be written as a minimax game:

EG − λED

max

D

min
F,G

min
D′

ED′

(4)

where λ is a hyper-parameter to trade off between transfer-
ability and discriminability. We utilize the well-established
gradient reversal layer proposed by Ganin et al. [6] to reverse

2723

the gradient between F and D to optimize all the modules
in an end-to-end training framework.

The testing phase of UAN is shown in the right plot of
Figure 2. Given each input target sample x, its categorical
prediction ˆy(x) over the source label set Cs, and the domain
prediction ˆd′(x), we compute wt(x) using Eq. (8) (details
in the next subsection). With a validated threshold w0, the
class y(x) can be predicted by thresholding ˆy(x) w.r.t. w0:

y(x) =(unknown

wt < w0
argmax (ˆy) wt ≥ w0

(5)

which either rejects the target sample x as “unknown” class
or classiﬁes it to one of the source classes.

3.4. Transferability Criterion

In this section, we further elaborate on how to compute
weighting ws = ws(x) and wt = wt(x) by sample-level
transferability criterion. With a proper sample-level transfer-
ability criterion, each point in both source and target domains
can be weighted such that the distributions of source and tar-
get data in the common label set C can be maximally aligned.
Also, data from target private label set Ct can be identiﬁed
and marked as “unknown” with the help of the sample-level
transferability criterion. Thus, a well-established sample-
level transferability criterion should satisfy Eq. (6):

E

E

x∼pC ws(x) > E
x∼qC wt(x) > E

ws(x)
wt(x)

x∼pCs

x∼qCt

(6)

These inequalities should hold in a non-negligible margin.

Now we need to construct the sample-level transferability
criterion. We ﬁrst list what we have at hand about each input
x: ˆy, ˆd, ˆd′. Since D is involved in adversarial training and
thus fooled, its output ˆd is not discriminative enough. We
thus analyze the properties of ˆy and ˆd′ as follows.

Domain Similarity. In Eq. (2), the objective of D′ is to
predict samples from source domain as 1 and samples from
target domain as 0. Thus, ˆd′ can be seen as the quantiﬁcation
for the domain similarity of each sample. For a source
sample, smaller ˆd′ means that it is more similar to the target
domain; for a target sample, larger ˆd′ means that it is more
similar to the source domain. Therefore, we can hypothesize
that E

ˆd′ > E

ˆd′ > E

ˆd′ > E

ˆd′.

x∼pC

x∼qC

x∼pCs

x∼qC

ˆd′, E

Due to the nature of D′, inequality E

E
the same label set, pC is closer to qC compared with qC t
it is reasonable to hypothesize E

ˆd′ >
ˆd′ naturally holds. Since pC and qC share
, and
ˆd′. The

ˆd′ > E

x∼pCs

x∼qCt

x∼pC

x∼qCt
ˆd′, E

x∼pCs

same observation applies to E

ˆd′ > E

x∼qC

x∼pC
ˆd′.

x∼qCt

criterion in semi-supervised learning and domain adaptation
[9, 23] to enforce the decision boundary in the unlabeled data
to pass through low-density area. In principle, entropy quan-
tiﬁes the prediction uncertainty, and smaller entropy means
H(ˆy) >
more conﬁdent prediction. We hypothesize: E
H(ˆy).

x∼qC H(ˆy) > E
Since the source domain is labeled and the target domain
is unlabeled, predictions are certain for source samples and
x∼qC H(ˆy) >
uncertain for target samples, E

x∼pC H(ˆy) > E

H(ˆy), E

x∼pCs

x∼qCt

E

x∼qCt

E

x∼pCs

H(ˆy).

x∼pC H(ˆy), E
Similar samples from qC and pC can attract each other.
Thus, the entropy of samples from pC becomes larger be-
cause they are inﬂuenced by the high entropy samples from
qC. Still, as Cs has no intersection with Ct, samples from pC s
are not inﬂuenced by the target data and keeps highest cer-
H(ˆy).
tainty. So we hypothesize that E
Similarly, Ct has no intersection with Cs (data from qC t
does not belong to any class in Cs), and thus the hypothesis
E

x∼pC H(ˆy) > E

x∼qC H(ˆy) is reasonable.

H(ˆy) > E

x∼pCs

x∼qCt

With the above analysis, the sample-level transferability
criterion for source data points and target data points can be
respectively deﬁned as Eq. (7) and Eq. (8):

ws(x) =

H(ˆy)
log |Cs|

− ˆd′(x)

wt(x) = ˆd′(x) −

H(ˆy)
log |Cs|

(7)

(8)

Note that the entropy is normalized by its maximum value
(log |Cs|) so that it is restricted into [0, 1] and comparable
to the domain similarity measure ˆd′. Also, the weights are
normalized into interval [0, 1] during training.

The proposed universal adaptation network (UAN) lever-
ages the sample-level transferability criterion to disentangle
source data in C, Cs and target data in C, Ct. As such, the
category gap is reduced. The domain gap is reduced as well
by aligning features between domains in shared label set C.

4. Experiments

To perform a thorough evaluation, we compare UAN with
state of the art methods tailored to various domain adaptation
settings under a variety of UDA settings on several datasets
with different ξ, |Cs ∪ Ct|, Ct and Cs. Then, we explore
the performance with respect to the change of ξ, |Cs ∪ Ct|,
Ct and Cs. We further provide comprehensive analyses of
the hyper-parameter sensitivity and the quality of sample-
level transferability criterion about the proposed UAN model.
Code and data will be available at github.com/thuml.

Prediction Uncertainty. The prediction ˆy contains the
discriminative information about the input, but it is only reli-
able in the source domain guaranteed by labeled data. To ex-
ploit unlabeled data, entropy minimization has been used as a

4.1. Experimental Setup

In this subsection, we describe the datasets, the evaluation

protocols and the implementation details.

2724

Table 1. Average class accuracy (%) of universal domain adaptation tasks on Ofﬁce-Home (ξ = 0.15) dataset (ResNet)

Method

ResNet [13]
DANN [6]
RTN [23]
IWAN [45]
PADA [45]

ATI [28]

OSBP [35]

UAN w/o d
UAN w/o y

UAN

Ofﬁce-Home

Ar → Cl Ar → Pr Ar → Rw Cl → Ar Cl → Pr Cl → Rw Pr → Ar Pr → Cl Pr → Rw Rw → Ar Rw → Cl Rw → Pr Avg

59.37
56.17
50.46
52.55
39.58
52.90
47.75

61.60
56.63
63.00

76.58
81.72
77.80
81.40
69.37
80.37
60.90

81.86
77.51
82.83

87.48
86.87
86.90
86.51
76.26
85.91
76.78

87.67
87.61
87.85

69.86
68.67
65.12
70.58
62.57
71.08
59.23

74.52
71.96
76.88

71.11
73.38
73.40
70.99
67.39
72.41
61.58

73.59
69.08
78.70

81.66
83.76
85.07
85.29
77.47
84.39
74.33

84.88
83.18
85.36

73.72
69.92
67.86
74.88
48.39
74.28
61.67

73.65
71.40
78.22

56.30
56.84
45.23
57.33
35.79
57.84
44.50

57.37
56.10
58.59

86.07
85.80
85.50
85.07
79.60
85.61
79.31

86.61
84.24
86.80

78.68
79.41
79.20
77.48
75.94
76.06
70.59

81.58
79.27
83.37

59.22
57.26
55.55
59.65
44.50
60.17
54.95

62.15
60.59
63.17

78.59
78.26
78.79
78.91
78.10
78.42
75.18

79.14
78.35
79.43

73.22
73.17
70.91
73.39
62.91
73.29
63.90

75.39
72.91
77.02

Table 2. Average class accuracy (%) on Ofﬁce-31 (ξ = 0.32), ImageNet-Caltech (ξ = 0.07) and VisDA2017 (ξ = 0.50) (ResNet)

Method

ResNet [13]
DANN [6]
RTN [23]
IWAN [45]
PADA [45]

ATI [28]

OSBP [35]

UAN

Ofﬁce-31

A → W

D → W

W → D

A → D

D → A

W → A

75.94
80.65
85.70
85.25
85.37
79.38
66.13

85.62

89.60
80.94
87.80
90.09
79.26
92.60
73.57

94.77

90.91
88.07
88.91
90.00
90.91
90.08
85.62

97.99

80.45
82.67
82.69
84.27
81.68
84.40
72.92

86.50

78.83
74.82
74.64
84.22
55.32
78.85
47.35

85.45

81.42
83.54
83.26
86.25
82.61
81.57
60.48

85.12

ImageNet-Caltech

I → C

C → I

70.28
71.37
71.94
72.19
65.47
71.59
62.08

75.28

65.14
66.54
66.15
66.48
58.73
67.36
55.48

70.17

VisDA

52.80
52.94
53.92
58.72
44.98
54.81
30.26

60.83

Avg

82.86
81.78
84.18
86.68
79.19
84.48
67.68

89.24

4.1.1 Datasets

Ofﬁce-31 [33] is de facto for visual domain adaptation with
31 categories in 3 visually distinct domains (A, D, W). We
use the 10 classes shared by Ofﬁce-31 and Caltech-256 [7]
as the common label set C, then in alphabetical order, the
next 10 classes are used as the Cs, and the reset 11 classes
are used as the Ct. Here ξ = 0.32.

Ofﬁce-Home [40] is a larger dataset with 65 object cate-
gories in 4 different domains: Artistic images (Ar), Clip-Art
images (Cl), Product images (Pr) and Real-World images
(Rw). In alphabet order, we use the ﬁrst 10 classes as C, the
next 5 classes as Cs and the rest as Ct. Here ξ = 0.15.

VisDA2017 [29] dataset focuses on a special domain
adaptation setting (simulation to real). The source domain
consists of images generated by game engines and target
domain consists of real-world images. There are 12 classes
in this dataset. We use the ﬁrst 6 classes as C, the next 3
classes as Cs and the rest as Ct. Here ξ = 0.50.

ImageNet-Caltech is built from ImageNet-1K [31] with
1000 classes and Caltech-256 with 256 classes. As in previ-
ous works [2, 3], we used the 84 common classes shared by
both domains as the common label set C and use their private
classes as the private label set respectively. This dataset nat-
urally falls into the universal domain adaptation paradigm.
We form two universal domain adaptation tasks: I → C and
C → I. Here ξ = 0.07.

These dataset settings are set up to both comply with the
existing conﬁgurations [2, 3, 35, 28] and cover as many com-
monness levels ξ as possible, since brute-force evaluation of
all combinations of ξ, |Cs ∪ Ct|, Ct and Cs is unacceptable.

4.1.2 Evaluation Details

Compared Methods. We compare the proposed UAN
with (1) Convolutional Neural Network: ResNet [13], (2)
close-set domain adaptation methods: Domain-Adversarial
Neural Networks (DANN) [6], Residual Transfer Networks
(RTN) [23], (3) partial domain adaptation methods: Im-
portance Weighted Adversarial Nets (IWAN) [45], Partial
Adversarial Domain Adaptation (PADA) [3], (4) open set do-
main adaptation methods: Assign-and-Transform-Iteratively
(ATI) [28], Open Set Back-Propagation (OSBP) [35]. These
methods are state of the art in their respective settings (ATI-λ
is compared and λ is derived as described in [28]). It shall
be valuable to study the performance of these methods in the
practical UDA setting.

Evaluation Protocols. We adopt the evaluation protocol
in Visual Domain Adaptation (VisDA2018) Open-Set Clas-
siﬁcation Challenge, where all the data in the target private
label set is regarded as one uniﬁed “unknown” class and the
average of per-class accuracy for all the |C| + 1 classes is
the ﬁnal result. We extend existing methods by conﬁdence
thresholding. At the testing stage, if the prediction conﬁ-

2725

90

80

70

y
c
a
r
u
c
c
A

60

50

0

90

80

y
c
a
r
u
c
c
A

70

60

50

31

ResNet
DANN
IWAN
OSBP
UAN

20 21

70

y
c
a
r
u
c
c
A

UAN

ResNet

DANN

IWAN

ATI-λ

5

0

60

−1.0

−0.8

−0.6

−0.4

−0.2

0.0

w0

ResNet
DANN
IWAN
OSBP
UAN
25

20

15

10

Size of Common Label Set

5

Size of Target Private Label Set

10

15

(a) Accuracy w.r.t. |Ct|

(b) Accuracy w.r.t. |C|

(c) Sensitivity to w0

Figure 3. (a) Accuracy w.r.t. |Ct| in task A → D, ξ = 0.32. (b) Accuracy w.r.t. |C| in task A → D. (c) Performance w.r.t. threshold w0.

dence is under the conﬁdence threshold, the input image is
classiﬁed as “unknown”.

Implementation Details. Implementation is in PyTorch
and ResNet-50 [13] is used as the backbone network. Models
are ﬁne-tuned from ResNet-50 pre-trained on ImageNet. We
set temperature [14] as 10 when calculating ˆy in Eq. (7)
because the prediction for source data is usually too certain
and the entropy is low. When applied in Eq. (3), ws, wt are
normalized in a mini-batch to be within interval [0, 1].

4.2. Classiﬁcation Results

The classiﬁcation results are shown in Tables 1 and 2,
respectively. UAN outperforms all the compared methods
in terms of the average per-class accuracy. In particular, we
have some key observations.

In the practical UDA setting, especially in the difﬁcult
Ofﬁce-Home dataset, most existing methods perform simi-
larly to or even worse than ResNet, indicating that existing
methods are prone to negative transfer in UDA settings,
meaning that they perform worse than a model only trained
on source data without any adaptation. For example, Fig-
ure 4(a) shows the per-class accuracy gain compared to
ResNet on task Ar → Cl. We can ﬁnd that DANN, IWAN,
and OSBP suffer from negative transfer in most classes and
are only able to promote the adaptation for a few classes.
Only UAN promotes positive transfer for all classes.

In these various settings, UAN outperforms all the men-
tioned methods. This is because UAN has a carefully de-
signed sample-level transferability criterion. It ﬁlters out
data coming from Ct and Cs on feature alignment and pro-
vides a better criterion for “unknown” class detection than
the existing conﬁdence thresholding method.

Existing methods perform well when their assumptions
hold but worse when violated. Take OSBP as an example, if
manually removing source private classes (invalid operation
since target labels are unknown), its accuracy is 89.1% on
Ofﬁce-31; however, if keeping source private classes (vio-
lating its assumption), its accuracy drops to 67.68%. As the
assumptions of previous open set DA methods are violated
in UDA, it is no wonder that their accuracies drop sharply.

4.3. Analysis on Different UDA Settings

Varying Size of Ct and Cs. With ﬁxed |Cs ∪ Ct| and ξ,
we explore the performance of methods mentioned above
on universal domain adaptation with the various sizes of Ct
(Cs also changes correspondingly) on task A → D in Ofﬁce-
31 dataset. As shown in Figure 3(a), UAN outperforms all
the compared methods on most sizes of Ct. In particular,
when |Ct| = 0, which is the partial domain adaptation set-
ting with Ct ⊂ Cs, the performance of UAN is comparable
to IWAN’s performance. And when |Ct| = 21, which is
the open set domain adaptation setting with Cs ⊂ Ct, the
performance of UAN is comparable to OSBP’s performance.
IWAN and OSBP both take advantage of the prior knowledge
about label sets and design modules to exploit the knowledge.
However, UAN can still catch up with them in their expert
settings, indicating UAN is effective and robust to diverse
sizes of Ct and Cs. In the middle of 0 and 21, where Cs and
Ct are partly shared, UAN outperforms other methods with
large margin. UAN can produce impressive results without
any prior knowledge about the target label set. The general
trend in Figure 3(a) is that the performance goes higher when
|Ct| becomes larger. This is natural since larger |Ct| means
smaller |Cs| and less distraction to the label classiﬁer.

Varying Size of Common Label Set C. We explore an-
other dimension of universal domain adaptation by varying
the size of C. This is done in Ofﬁce-31 dataset on task A
→ D. Here |C| + |Ct| + |Cs| = 31. For simplicity, we let
|Ct| = |Cs| + 1 and vary |C| from 0 to 31. Figure 3(b) shows
the accuracy of these methods with different |C|’s. When
|C| = 0, source domain and target domain have no overlap
on label sets, i.e. Ct ∩ Cs = ∅. We observe that UAN sub-
stantially outperforms all the compared methods with large
margin, because they all assume that there is some common
label set between source and target domains and cannot ﬁlter
out target samples well when all the target samples are in the
private label set Ct. When |C| = 31, which is the closed set
domain adaptation setting with Cs = Ct, we see that the per-
formance of UAN is comparable with DANN’s performance,
indicating that the sample-level transferability criterion of

2726

N
N
A
D

N
A
W

I

P
B
S
O

N
A
U

10
0
-10
-20
-30

10
0
-10
-20
-30

10
0
-10
-20
-30

10
0
-10
-20
-30

i

y
t
n
a
t
r
e
c
n
U

y
t
i
r
a

l
i

m
S

i

i

n
a
m
o
D

y
t
i
l
i

b
a
r
e
f
s
n
a
r
T

0

1

2

3

4
5
class

6

7

8

9

−1

0

source

1

−1

0

target

1

(a) Negative Transfer in UDA

(b) Hypotheses Quality (blue for common and black for private)

Figure 4. (a) The negative transfer inﬂuence in UDA (task Ar → Cl). (b) Justiﬁcation of validity of hypotheses in Section 3.4.

UAN preserves useful samples and does not inﬂuence per-
formance on the closed set domain adaptation setting. Note
that when |C| keeps decreasing, the performance of DANN
and IWAN drops rapidly and only UAN works stably.

4.4. Analysis of Universal Adaptation Network

Ablation Study. We go deeper into the efﬁcacy of the
proposed sample-level transferability criterion by perform-
ing an ablation study that evaluates variants of UAN. (1)
UAN w/o d is the variant without integrating the domain
similarity into the sample-level transferability criterion in
Eq. (7) and Eq. (8); (2) UAN w/o y is the variant without
integrating the uncertainty criterion into sample-level trans-
ferability criterion in Eq. (7) and Eq. (8). Results are shown
in bottom rows of Table 1. UAN outperforms UAN w/o d and
UAN w/o y, indicating both the domain similarity compo-
nent and the uncertainty criterion component in the deﬁnition
of ws(x), wt(x) are important and necessary. In addition,
UAN w/o d performs better than UAN w/o y, meaning that
integrating the uncertainty criterion into the sample-level
transferability criterion is even more crucial.

Hypotheses Justiﬁcation. To justify the validity of the
hypotheses in Section 3.4, we plot in Figure 4(b) the esti-
mated probability density function for different components
of weights ws(x) in Eq. (7) and wt(x) in Eq. (8). Results
show that all the hypotheses are successfully justiﬁed, ex-
plaining why UAN can perform well in various UDA settings.
Another observation is that the uncertainty criterion and the
domain similarity themselves can be used to distinguish all
the examples from common label set and private label sets.
By combining these two components we can obtain more
distinguishable transferability criterion.

Threshold Sensitivity. We explore the sensitivity of
UAN with respect to threshold w0 in task I → C. As shown
in Figure 3(c), though UAN’s accuracies vary by about 2%
w.r.t. w0, it consistently outperforms the other methods by
large margins in a wide range of w0. Note that the baselines
are fully tuned and their best accuracies are compared here.

5. Conclusion

In this paper, we introduce a novel Universal Domain
Adaptation (UDA) setting, where no prior knowledge are
required on the label set relationship between domains. We
propose Universal Adaptation Network (UAN) with a well-
designed sample-level transferability criterion to address
UDA. A thorough evaluation shows that existing methods
requiring prior knowledge on the relationship of label sets
cannot work well in general UDA setting while the proposed
UAN works stably and achieves state-of-the-art results.

In practice, if one wants to generalize a model to a new
scenario, the proposed UAN can be a good candidate model.
If UAN classiﬁes most examples as “unknown”, then domain
adaptation in such a new scenario may well fail, and collect-
ing labels will be indispensable. On the other hand, if UAN
can generate labels for most examples, collecting labels for
such a scenario are not necessary and domain adaptation will
perform the work. That said, UAN can serve as a pilot study
when we encounter a new domain adaptation scenario.

Acknowledgements

This work is supported by National Key R&D Program of
China (No. 2017YFC1502003) and National Natural Science
Foundation of China (61772299, 71690231, and 61672313).

2727

References

[1] B. Bhushan Damodaran, B. Kellenberger, R. Flamary,
D. Tuia, and N. Courty. Deepjdot: Deep joint dis-
tribution optimal transport for unsupervised domain
adaptation. In ECCV, September 2018.

[2] Z. Cao, M. Long, J. Wang, and M. I. Jordan. Partial
transfer learning with selective adversarial networks.
In CVPR, June 2018.

[3] Z. Cao, L. Ma, M. Long, and J. Wang. Partial adver-
sarial domain adaptation. In ECCV, pages 135–150,
2018.

[4] Q. Chen, Y. Liu, Z. Wang, I. Wassell, and K. Chetty.
Re-weighted adversarial adaptation network for unsu-
pervised domain adaptation. In CVPR, pages 7976–
7985, 2018.

[5] L. Duan, I. W. Tsang, and D. Xu. Domain transfer mul-

tiple kernel learning. TPAMI, 34(3):465–479, 2012.

[6] Y. Ganin, E. Ustinova, H. Ajakan, P. Germain,
H. Larochelle, F. Laviolette, M. Marchand, and V. S.
Lempitsky. Domain-adversarial training of neural net-
works. JMLR, 17:59:1–59:35, 2016.

[7] B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic
ﬂow kernel for unsupervised domain adaptation. In
CVPR, 2012.

[8] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu,
D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio.
Generative adversarial nets. In NeurIPS, pages 2672–
2680, 2014.

[9] Y. Grandvalet and Y. Bengio. Semi-supervised learning
by entropy minimization. In NeurIPS, pages 529–536,
2004.

[10] C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger. On
calibration of modern neural networks. In International
Conference on Machine Learning, pages 1321–1330.

[11] P. Haeusser, T. Frerix, A. Mordvintsev, and D. Cremers.
Associative domain adaptation. In ICCV, volume 2,
page 6, 2017.

[12] K. He, G. Gkioxari, P. Dollár, and R. Girshick. Mask

r-cnn. In ICCV, pages 2980–2988. IEEE, 2017.

[13] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual

learning for image recognition. In CVPR, 2016.

[14] G. Hinton, O. Vinyals, and J. Dean. Distilling the

knowledge in a neural network.

[15] J. Hoffman, E. Tzeng, T. Park, J. Zhu, P. Isola,
K. Saenko, A. A. Efros, and T. Darrell. Cycada: Cycle-
consistent adversarial domain adaptation. In ICML,
pages 1994–2003, 2018.

[16] L. Hu, M. Kan, S. Shan, and X. Chen. Duplex gen-
erative adversarial network for unsupervised domain
adaptation. In CVPR, June 2018.

[17] S.-W. Huang, C.-T. Lin, S.-P. Chen, Y.-Y. Wu, P.-H.
Hsu, and S.-H. Lai. Auggan: Cross domain adaptation
with gan-based data augmentation. In ECCV, Septem-
ber 2018.

[18] G. Kang, L. Zheng, Y. Yan, and Y. Yang. Deep ad-
versarial attention alignment for unsupervised domain
adaptation: the beneﬁt of target expectation maximiza-
tion. In ECCV, September 2018.

[19] B. Konstantinos, S. Nathan, D. David, E. Dumitru, and
K. Dilip. Unsupervised pixel–level domain adaptation
with generative adversarial networks. In CVPR, pages
95–104, 2017.

[20] Y.-C. Liu, Y.-Y. Yeh, T.-C. Fu, S.-D. Wang, W.-C. Chiu,
and Y.-C. Frank Wang. Detach and adapt: Learning
cross-domain disentangled deep representation.
In
CVPR, June 2018.

[21] M. Long, Y. Cao, J. Wang, and M. I. Jordan. Learning
transferable features with deep adaptation networks. In
ICML, 2015.

[22] M. Long, Z. Cao, J. Wang, and M. I. Jordan. Condi-
tional domain adversarial network. In NeurIPS, 2018.

[23] M. Long, H. Zhu, J. Wang, and M. I. Jordan. Un-
supervised domain adaptation with residual transfer
networks. In NeurIPS, pages 136–144, 2016.

[24] Z. Luo, Y. Zou, J. Hoffman, and L. F. Fei-Fei. Label ef-
ﬁcient learning of transferable representations acrosss
domains and tasks. In NeurIPS, pages 165–177, 2017.

[25] F. Maria Carlucci, L. Porzi, B. Caputo, E. Ricci, and
S. Rota Bulo. Autodial: Automatic domain alignment
layers. In ICCV, Oct 2017.

[26] Z. Murez, S. Kolouri, D. Kriegman, R. Ramamoorthi,
and K. Kim. Image to image translation for domain
adaptation. In CVPR, June 2018.

[27] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang.
Domain adaptation via transfer component analysis.
TNNLS, 22(2):199–210, 2011.

[28] P. Panareda Busto and J. Gall. Open set domain adap-

tation. In ICCV, Oct 2017.

[29] X. Peng, B. Usman, N. Kaushik, D. Wang, J. Hoffman,
K. Saenko, X. Roynard, J.-E. Deschaud, F. Goulette,
and T. L. Hayes. VisDA: A synthetic-to-real benchmark
for visual domain adaptation. In CVPR Workshops,
pages 2021–2026.

[30] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: To-
wards real-time object detection with region proposal
networks. In NeurIPS, pages 91–99.

[31] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh,
S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein,
A. C. Berg, and L. Fei-Fei.
ImageNet Large Scale
Visual Recognition Challenge. IJCV, 115(3):211–252,
2015.

2728

[32] P. Russo, F. M. Carlucci, T. Tommasi, and B. Ca-
puto. From source to target and back: Symmetric
bi-directional adaptive gan. In CVPR, June 2018.

[48] J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros. Unpaired
image-to-image translation using cycle-consistent ad-
versarial networks. In ICCV, pages 2242–2251, 2017.

[33] K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting
In ECCV,

visual category models to new domains.
2010.

[34] K. Saito, K. Watanabe, Y. Ushiku, and T. Harada. Max-
imum classiﬁer discrepancy for unsupervised domain
adaptation. In CVPR, June 2018.

[35] K. Saito, S. Yamamoto, Y. Ushiku, and T. Harada.
Open set domain adaptation by backpropagation. In
ECCV, September 2018.

[36] S. Sankaranarayanan, Y. Balaji, C. D. Castillo, and
R. Chellappa. Generate to adapt: Aligning domains
using generative adversarial networks. In CVPR, June
2018.

[37] E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell. Ad-
versarial discriminative domain adaptation. In CVPR,
2017.

[38] E. Tzeng, J. Hoffman, N. Zhang, K. Saenko, and T. Dar-
rell. Deep domain confusion: Maximizing for domain
invariance. arXiv preprint arXiv:1412.3474, 2014.

[39] E. Tzeng, J. Hoffman, N. Zhang, K. Saenko, and T. Dar-
rell. Simultaneous deep transfer across domains and
tasks. In ICCV, 2015.

[40] H. Venkateswara, J. Eusebio, S. Chakraborty, and
S. Panchanathan. Deep hashing network for unsuper-
vised domain adaptation. In CVPR, 2017.

[41] R. Volpi, P. Morerio, S. Savarese, and V. Murino. Ad-
versarial feature augmentation for unsupervised do-
main adaptation. In CVPR, June 2018.

[42] X. Wang and J. Schneider. Flexible transfer learning

under support and model shift. In NeurIPS, 2014.

[43] S. Xie, Z. Zheng, L. Chen, and C. Chen. Learning se-
mantic representations for unsupervised domain adap-
tation. In ICML, pages 5423–5432, 2018.

[44] W. Zellinger, T. Grubinger, E. Lughofer, T. Natschläger,
and S. Saminger-Platz. Central moment discrepancy
(CMD) for domain-invariant representation learning.
In ICLR.

[45] J. Zhang, Z. Ding, W. Li, and P. Ogunbona. Importance
weighted adversarial nets for partial domain adaptation.
In CVPR, June 2018.

[46] K. Zhang, B. Schölkopf, K. Muandet, and Z. Wang.
Domain adaptation under target and conditional shift.
In ICML, 2013.

[47] W. Zhang, W. Ouyang, W. Li, and D. Xu. Collabora-
tive and adversarial network for unsupervised domain
adaptation. In CVPR, June 2018.

2729

