Weakly Supervised Image ClassiÔ¨Åcation through Noise Regularization

Mengying Hu1

,

3, Hu Han1

2

,

,

‚àó, Shiguang Shan1

2

,

,

3

,

4, Xilin Chen1

3

,

1 Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS),

Institute of Computing Technology, CAS, Beijing 100190, China

2 Peng Cheng Laboratory, Shenzhen, China

3 University of Chinese Academy of Sciences, Beijing 100049, China

4 CAS Center for Excellence in Brain Science and Intelligence Technology, Shanghai, China

mengying.hu@vipl.ict.ac.cn, {hanhu, sgshan, xlchen}@ict.ac.cn

Abstract

Weakly supervised learning is an essential problem in
computer vision tasks, such as image classiÔ¨Åcation, objec-
t recognition, etc., because it is expected to work in the
scenarios where a large dataset with clean labels is not
available. While there are a number of studies on weakly
supervised image classiÔ¨Åcation, they usually limited to ei-
ther single-label or multi-label scenarios. In this work, we
propose an effective approach for weakly supervised image
classiÔ¨Åcation utilizing massive noisy labeled data with only
a small set of clean labels (e.g., 5%). The proposed ap-
proach consists of a clean net and a residual net, which
aim to learn a mapping from feature space to clean la-
bel space and a residual mapping from feature space to
the residual between clean labels and noisy labels, respec-
tively, in a multi-task learning manner. Thus, the residu-
al net works as a regularization term to improve the clean
net training. We evaluate the proposed approach on two
multi-label datasets (OpenImage and MS COCO2014) and
a single-label dataset (Clothing1M). Experimental results
show that the proposed approach outperforms the state-of-
the-art methods, and generalizes well to both single-label
and multi-label scenarios.

1. Introduction

Weakly supervised learning is receiving increasing atten-
tion in many computer vision tasks, e.g., image classiÔ¨Åca-
tion, object recognition, etc., because incomplete and inac-
curate annotations widely exist in many practical scenarios.
For example, the diverse knowledge levels of different sub-
jects can lead to different understanding of the same classes
of images. In addition, a massive dataset may be collected
automatically, and annotated by pre-trained models to re-

‚àóCorresponding author.

Figure 1. An illustration of distinguishing between the reliable and
unreliable parts in the massive noisy labels based on assumptions,
such as label-to-label relationship and image-to-label relationship.
The green and yellow lines denote positive and negative correla-
tion, respectively. The thickness of a line denotes the strength of
the correlation.

duce the cost in annotation time and expense, and only a
small set of the labels can be veriÔ¨Åed by humans. It is chal-
lenging for the traditional supervised learning methods to
work on such datasets with noisy labels. Therefore, weakly
supervised learning from noisy data becomes valuable for
practical applications and has drawn increasing attentions
in recent years [5, 10, 11, 14, 25, 30].

Existing weakly supervised learning methods on im-
age classiÔ¨Åcation usually have certain assumptions with the
noise label type, i.e., single-label noise or multi-label noise.
Patrini et al. [23] deÔ¨Åned a matrix T to describe the Ô¨Çipping
relation between each two classes under the single label as-
sumption. Veit et al. [30] implicitly learned a structure in
the label space to do the prediction of multi-label. Both as-
sumptions have their own characteristics. Single-label noise
can introduce methods like clustering similar images in the
training process [14] while multi-label noise can use label-

111517

Decision processcup, appleapplebowlT-shirthoodieT-shirtT-shirthoodiecupapplecupbowlto-label relation to make the algorithm more robust [33].
Although these assumptions help to improve the model per-
formance, it limits the generalization ability of model from
single-label dataset to multi-label dataset. For single-label
noise learning methods [14, 23, 34], they cannot be applied
to the multi-label data due to their strict assumption. For
multi-label noise learning methods [20, 30, 33], their effec-
tiveness on the single-label data is unknown.

In this work, we focus on reconciling the gap between
single-label and multi-label in weakly supervised image
classiÔ¨Åcation. In our observation, although previous meth-
ods use different assumptions to assist in classiÔ¨Åer learning,
the key idea of them is to distinguish between the reliable
and unreliable parts in the massive noisy labels, e.g., learn-
ing a mapping from noisy label space to clean label space or
Ô¨Åltering out some noisy labels by utilizing the characteristic
of noise. As shown in Fig. 1, for methods which use as-
sumptions of label-to-label or image-to-label relationship,
the reliable and unreliable parts of the noisy labels are de-
termined by the strength of positive or negative correlations.

In this paper, we propose a weakly supervised learning
approach for image classiÔ¨Åcation that can automatically i-
dentify the reliable labels from the massive noisy labels. We
expect that the proposed method can leverage massive noisy
labeled data with a small set of clean labels to obtain a more
robust image classiÔ¨Åcation model. In addition, we expect
that the proposed approach can generalize to both single-
label and multi-label image classiÔ¨Åcation. An overview of
our approach is shown in Fig. 2. The proposed approach
consists of a stem net (i.e., ResNet-50), a clean net, and a
residual net. The stem net is used for shared feature learn-
ing. The clean net and the residual net are responsible for
learning a mapping from feature space to clean label space
and a residual mapping from feature space to the residual
between clean labels and noisy labels, respectively. Simi-
lar to [11, 30], we only use a small fraction of dataset with
clean labels to assist in the network training. We supervise
the clean net using only the clean labels, and supervise the
sum of clean net and residual net using noisy labels, re-
spectively. The residual net works as a regularization term
to improve the clean net training so that it can utilize the
reliable information among the massive noisy data, while
avoiding big inÔ¨Çuence by the unreliable information. Ex-
perimental results show that the proposed approach outper-
forms the state-of-the-art methods, and generalizes well to
both single-label and multi-label scenarios.

Our contributions are as follows. (i) Our approach mod-
els the noisy label distribution via a residual net, and uses
it to regularize the training of clean net so that the clean
net can leverage the reliable part in the massive noisy da-
ta to improve the classiÔ¨Åcation performance. (ii) Our ap-
proach has good generalization ability, and can work for
both single-label and multi-label image classiÔ¨Åcation tasks.

2. Related Work

Most of the weakly supervised image classiÔ¨Åcation
methods aim to learn from data with only noisy labels. One
category of methods aims to distinguish the noise data from
the entire dataset [2, 14, 17, 18, 24, 28, 32]. These meth-
ods usually focus on Ô¨Ånding the difference between noisy
data and clean data. Brodley and Friedl [2] used a set of
classiÔ¨Åers to do outliers removal before training, under the
assumption that outliers are likely noisy data. Reed et al.
[24] used a bootstrap technique which could dynamically
update the supervision under a prediction consistency as-
sumption to Ô¨Ålter out the potential noisy labels. Wang et al.
[32] used contractive loss to distinguish between data with
noisy labels and data with clean labels. Lee et al. [14] in-
troduced a reference set to get a representative of the noisy
set and used it for noise detection and image classiÔ¨Åcation.
Another category of weakly supervised learning meth-
ods is to explore the new design of loss function [1, 6, 19,
21, 23] or network architecture [20, 22, 26] to achieve noise
robust learning. These methods do not aim to separate noisy
labels from all the labels explicitly. Instead, they incorpo-
rated the label transition process into the classiÔ¨Åcation net-
work design and aimed at learning a robust end-to-end clas-
siÔ¨Åcation model. Sukhbaatar et al. [26] used a single linear
layer to model the label transition process from clean la-
bels to noisy labels, while Patrini et al. [23] replaced the
layer with estimating a noise transition matrix. Misra et al.
[20] proposed an image-based probability model on multi-
label noise to describe the relation between visually present
(clean) labels and human-centric (noisy) labels.

Our method belongs to another stream, which under the
assumption that few clean labels are known [11, 30, 34].
These methods aim at leveraging massive noisy labeled da-
ta with a small set of clean labels to learn a robust image
classiÔ¨Åer. [10, 30] proposed a teacher-student framework
with a label cleaning network to achieve noisy label learn-
ing. Xiao et al. [34] built a probability model to describe
the generating process of noisy labels and used the data with
clean labels to pre-train the network. Li et al. [15] distilled
the knowledge in the clean labels and used it to avoid over-
Ô¨Åtting to noisy labels. Compared with learning from data
with noisy labels solely, clean labels can guide the model
to the right direction to some extent. Experimental results
in these works showed that even a small set of clean labels
have a positive inÔ¨Çuence on performance improvement. Our
method is similar to [15], but we use the data with noisy la-
bels to reduce the risk of overÔ¨Åtting to the data with clean
labels under a more generalized framework instead of the
single label classiÔ¨Åcation assumption in [15].

Apart from using a small set of clean labels, several
studies also introduced side-information (e.g., knowledge
graph) to assist in improving model robustness toward noisy
labels [3, 15, 33]. Wu et al. [33] used a mixed dependency

11518

Figure 2. An overview of the proposed approach for weakly supervised image classiÔ¨Åcation, which consists of a shared feature extractor
(i.e., ResNet-50), a clean net, and a residual net. The clean net and the residual net are responsible for learning a mapping (Fc) from
feature space to clean label space and a residual mapping (Fr) from feature space to the residual between clean labels and noisy labels,
respectively. We train two classiÔ¨Åers h and g using the noisy labels in the noisy set and the clean labels in the clean set, respectively. h is
supervised by the noisy labels yi for all samples xi in Dn in terms of Lnoise, and g is supervised by the clean labels vj for all samples xj
in Dc in terms of Lclean. Residual net r with classiÔ¨Åer h works as a regularization term in training the clean net c with classiÔ¨Åer g.

graph modeling the semantic hierarchical dependency be-
tween labels to complete the missing labels by label propa-
gation. Li et al. [15] introduced a label-to-label graph en-
coding the structure in label space to avoid over-certainty
of the data with clean labels. However, side-information
is sometimes highly related to the label set, which also re-
stricts the generalization ability of model to some extent.

3. Our Approach

3.1. Problem Formulation

Our goal is to leverage massive noisy labeled data with a
small set of clean labels to obtain a robust image classiÔ¨Åca-
tion model. We also expect that the model does not require
assumptions about the label type, and can generalize to both
single-label and multi-label image classiÔ¨Åcation tasks.

Let D = Dn ‚à™ Dc denote the entire training dataset,
where Dn = {(xi, yi)|i = 1, ..., Nn} and Dc =
{(xj, vj)|j = 1, ..., Nc} are the dataset with noisy label-
s and the dataset with clean labels, respectively; xi and yi
in Dn denote the i-th image and corresponding noisy label;
Nn denote the total image number in Dn; xj and vj in Dc
denote the j-th image and corresponding clean label; Nc
denote the total image number of Dc. It should be noted
that noisy labels for images in Dc are not required. In this
work, we do not make any assumptions about noisy label
type, i.e., single-label or multi-label data. In practical ap-
plications, we can assume the number of images with clean
labels is much less than the noisy data, i.e., Nc ‚â™ Nn.

As shown in Fig. 2, we leverage multi-task learning [7,
8, 31] to perform weakly supervised image classiÔ¨Åcation,

which train two classiÔ¨Åers g and h to Ô¨Åt the clean labels
in clean set and the noisy labels in noisy set, respectively.
The backbone CNN (i.e., a ResNet50 [9] or Inception V3
[27]) is used to learn a mapping from image space x to the
feature space f (e.g., pool5). The features are shared by the
residual net and the clean net.

Both the clean net and the residual net contain a non-
linear transformation which works as an activation layer
between two linear layers. The activation layer could be
a common used non-linear activate function, such as ReLU,
tanh and sigmoid. We will provide the performance with
different activation functions in detail in experiments. This
non-linear transformation is used to learn a mapping from
feature space to clean label space or to noisy label space.
The reason why non-linear activation works better than lin-
ear is that the shared feature space f may not provide the
discriminative ability for both the samples with clean labels
and the samples with noisy labels simultaneously.

3.2. Residual Net for Noise Regularization

ClassiÔ¨Åer g, together with the shared backbone CNN and
the clean net, is the Ô¨Ånal image classiÔ¨Åer that the proposed
approach aims to learn. It is used to learn a mapping from
feature space to clean label space. Let‚Äôs denote the map-
ping as Fc and the output of clean net as c; then c can be
represented as

c = Fc(f (x)).

Similarly, classiÔ¨Åer g can be represented as

g = œÉ(c),

(1)

(2)

11519

Classifier ùëîClassifier ‚ÑéClean Set  ùê∑ùëêFeature(ùëì)Noisy Set   ùê∑ùëõBackboneCNNlinearactivationlinearImageùë•ùëñClean label ùë£ùëóImage batchlinearactivationlinearsupervisedby ùêøùëêùëôùëíùëéùëõsupervisedby ùêøùëõùëúùëñùë†ùëíClean net(ùêπùëê)Residual net(ùêπùëü)Noisy label ùë¶ùëñImage ùë•ùëósigmoidsigmoidùëêùëüwhere œÉ is a sigmoid function. Only using the data in clean
set to train classiÔ¨Åer g makes g is prone to overÔ¨Åt since the
size of clean set can be very small in practical scenarios.
Therefore, we introduce classiÔ¨Åer h, which is expected to
serve as a regularization term w.r.t. classiÔ¨Åer g.

SpeciÔ¨Åcally, h is used to learn the residual mapping from
feature space to the residual between clean labels and noisy
labels. Let‚Äôs denote the residual mapping as Fr and the out-
put of residual net as r; then r can be represented as

r = Fr(f (x)).

Similarly, h can be represented as

h = œÉ(r + c),

(3)

(4)

where œÉ is a sigmoid function. In our experiments, we Ô¨Ånd
that summing the values of r and c up before applying sig-
moid function helps the network to have a better conver-
gence. So we do the sum operation before sigmoid. We do
not need to explicitly distinguish between the multi-label
and single label data. Therefore, we use a sigmoid function
to generate the probability for both scenarios.

The reason why h can be regarded as a noise regular-
ization term for g is the same as that why use regularization
methods, such as weight decay, early stopping and drop out,
during network training. They are all helpful to relieve the
overÔ¨Åtting problem. Through the above discussion, we can
see that the proposed residual net can model the unreliable
part in the massive noisy data and then in turn can let clas-
siÔ¨Åer g to make use of the reliable part in the massive noisy
data to achieve more robust image classiÔ¨Åcation.
In this
way, the residual net works as a regularization term to re-
lieve the overÔ¨Åtting issue with the classiÔ¨Åer g.

The proposed approach learns a mapping from clean la-
bel space to noisy label space conditioned on unreliable in-
formation in the noisy labels. From the perspective of learn-
ing the relation between these two label spaces, it is simi-
lar to using label transition model. However, unlike mod-
eling the label transition process explicitly, which usually
requires paired noisy-clean label for the samples in clean
set, our approach does not require such kind of paired data.
Using the clean net and the residual net, our approach can
explore the relation between clean labels and noisy labels
from unpaired data. Therefore, the two classiÔ¨Åers g and h
can be trained separately. This makes it possible for the pro-
posed approach to work under a wide range of applications.

3.3. Network Training

Both h and g are trained with binary cross-entropy loss.
The difference lies in the input images are different. h is
supervised by the noisy label yi for all samples i in Dn
while g is supervised by the clean label vj for all samples j
in Dc. We denote the loss of h and g as Lnoise and Lclean,

respectively, and they can be formulated as follows

Lnoise = ‚àí

Lclean = ‚àí

1
Nn

1
Nc

(yiln(hi) + (1 ‚àí yi)ln(1 ‚àí hi)),

(5)

X

i‚ààDn

(vj ln(gj) + (1 ‚àí vj)ln(1 ‚àí gj)),

(6)

X

j‚ààDc

where hi and gj are the predictions by classiÔ¨Åers h and g for
the corresponding image samples xi and xj , respectively.

Given the above deÔ¨Ånitions, the overall objective during

our network training can be formulated as

arg min

Œ±Lclean + Lnoise,

(7)

W

where W denotes the parameters of the network and Œ± de-
notes the trade-off parameter between two losses. Follow-
ing [30], to train classiÔ¨Åers g and h jointly leveraging the
massive noisy labeled data and a small set of clean labeled
data. In each batch during network training, we choose sam-
ples from both Dc and Dn in a ratio of 1:9.

We initialize the backbone CNN by the weights of Ima-
geNet pre-trained model. We use different training schemes
on multi-label and single-label data. For multi-label image
classiÔ¨Åcation, we Ô¨Årst Ô¨Åne-tune the backbone CNN by us-
ing the noisy labeled data and then only train the clean net
and the residual net. For single-label image classiÔ¨Åcation,
we directly Ô¨Åne-tune the whole network.

4. Experimental Results

4.1. Datasets

MS COCO2014 dataset [16] is designed for image
classiÔ¨Åcation, object detection, and semantic segmentation
tasks, which contains about 120K images of 80 classes. We
do not use origin MS COCO2014 dataset directly, because it
lacks the noisy labels. Following the idea of semi-automatic
image annotation in [11, 30], we use an ImageNet [4] pre-
trained Inception V3 [27] model to generate annotations for
all the images. SpeciÔ¨Åcally, we Ô¨Årst map the classes in Im-
ageNet to the classes in MS COCO and remove the classes
which do not appear in ImageNet, obtaining a label set with
56 classes, the mapped labels are clean labels. Then we use
Inception V3 to generate the top-8 predictions for each im-
age in the origin MS COCO dataset and map them to the
56 label classes. These automatically generated labels can
be viewed as the noisy labels. We remove the unlabeled
images and Ô¨Ånally obtain three sets for train, validation and
test, with size of 68,213, 16,714 and 16,763 images, respec-
tively. 1 Among the 68,213 training images, we assume on-
ly a small set of images (e.g., 5%) have clean labels during
image classiÔ¨Åcation model learning, and all the remaining
images only have noisy labels.

1We plan to put the MS COCO dataset we compiled into public domain.

11520

Dataset
MS COCO2014
OpenImage
Clothing1M

# Classes

# Train Imgs.

# Val/Test Imgs.

56

6,012

14

68K/68K
9M/40K
1M/50K

16K/16K
‚Äì/120K
14K/10K

Table 1. Evaluations protocols used for the MS COCO2014, Open-
Image, and Clothing1M databases.

OpenImage dataset [13] is a public multi-label dataset
for image classiÔ¨Åcation. It contains more than 9M images
with machine annotated labels from 6,012 unique classes.
There are many versions of this dataset since it was pro-
posed. We adopt the Ô¨Årst version to evaluate our approach.
It contains 9,011,219 images in training set (data with noisy
labels) and 167,056 images in validation set (data with both
noisy and clean labels). Following the partition in [30], we
use the whole training set and a quarter of validation set
(about 40K images) to train the model and the remain im-
ages in validation set to test.

Clothing1M dataset [34] is a widely used dataset for
single-label noise learning. It was proposed by [34] in 2015.
It contains 100M clothe images with noisy labels from 14
classes. Different from the noisy label type in OpenImage
and the compiling of MS-COCO, which was annotated by
pre-train model, labels in Clothing1M are corrupted by real-
world noise. According to [34], the noisy label of each im-
age in this dataset is assigned by the keyword of its sur-
rounding text. For the images with clean labels, it was split
into train, validation, and test, with size of 50K, 14K and
10K, respectively. We adopt this protocol for consistency
with state-of-the-art methods. [14, 23, 34].

4.2. Training Details

The proposed approach and all the baseline approach-
es are implemented with TensorÔ¨Çow. We use Inception
V3 model as the backbone network for OpenImage and
ResNet50 model as the backbone network for MS COCO
and Clothing1M. Since MS COCO is a dataset compiled
by ourselves, we report the results by the reimplement-
ed baseline methods while using the reported results [30]
and [14, 23] on OpenImage and Clothing1M, respective-
ly. On the MS COCO dataset, we Ô¨Årst use all the images
with noisy/clean labels to train the ResNet50 (Noisy/GT)
for 20,000 iterations using a batch size of 64 optimized by
RMSProp [29]. The learning rate is initialized with 10‚àí4
and decayed by 0.9 every 2 epochs. To evaluate the model
performance under a small set of data with clean labels, we
use 5%, 10%, and 20% samples from the entire training set
to form the clean set. We Ô¨Ånd the state-of-the-art method by
Veit et al. [30] (WP / TJ) is hard to converge on MS COCO
when it is optimized by RMSProp. For a fair comparison,
we optimize all the models by Adam [12] using a batchsize
of 32. We use a learning rate of 10‚àí4 to Ô¨Åne-tune the models

for 50,000 addition iterations. We use two pairs of learning
rate ((10‚àí4,10‚àí5) for 5%, 10%, (10‚àí3,10‚àí4) for 20%) to
train the method by Veit et al. [30] (WP / TJ) for 200,000
iterations. For the proposed method, we use a learning rate
of 10‚àí4 for sigmoid function and a learning rate of 10‚àí5
for tanh and ReLU , and with up to 100,000 iterations. The
trade-off parameter Œ± empirically set to 0.2.

On the OpenImage dataset, we train the proposed
method with a learning rate of 10‚àí3 using RMSProp op-
timizer using a batch size of 32 and up to 2M iterations. We
set the trade-off parameter Œ± = 0.1. Since not all of the
classes in the images of clean set have the clean labels, we
just Ô¨Åt the classes which have clean labels. On the Cloth-
ing1M dataset, we use a learning rate of 10‚àí4 and optimize
the model by Adam using a batch size of 32, and up to
120,000 iterations. We set the trade-off parameter Œ± = 0.2.

4.3. Metrics

For multi-label image classiÔ¨Åcation, we use the mean of
class-average precision (mAP) and the class agnostic aver-
age precision (APall) to evaluate the performance for con-
sistency with [30]. For each binary classiÔ¨Åcation problem,
we compute an AP to reÔ¨Çect the prediction precision of pos-
itive labels, which can be written as

APc =

1
m

n

X

i=1

P re(i, c) ¬∑ I(i, c),

(8)

where m and n denote the number of positive labels and
test samples, respectively. P re(i, c) denotes the precision
of class c at rank i. I(i, c) is an indicator function with 1
denoting the positive label‚Äôs presence of class c at rank i.
mAP is the mean of APc across all classes while APall is
the AP which treats all classes as a single class by ignoring
the class annotations.

For single-label image classiÔ¨Åcation, we follow the state-
of-the-art single-label noise learning methods [14, 23], and
report the top-1 accuracy.

4.4. Results for Multi label Image ClassiÔ¨Åcation

We Ô¨Årst conduct experiments on MS COCO [16] and
OpenImage [13] for multi-label image classiÔ¨Åcation. We
compare it with the state-of-the-art method [30]. Since the
source code of [30] is not publicly available, we implement-
ed it based on our best understanding, and achieves similar
results (62.17% mAP and 89.15% APall) to that in [30] on
OpenImage [13]. We use WP and TJ to denote the two vari-
ants (with pre-training, trained jointly) in [30], respectively.
We also provide the results of several related baselines.

Backbone (Noisy): A backbone network is trained
for multi-label classiÔ¨Åcation using all the noisy labels in
dataset. This can be viewed as a lower bound of all methods
which use clean labels.

11521

Method

Backbone (Noisy)
Backbone (Noisy-FT-W)
Backbone (Noisy-FT-L)
Backbone (Noisy-FT-M)
Veit et al. [30] (WP)
Veit et al. [30] (TJ)
Proposed (sigmoid)
Proposed (tanh)
Proposed (ReLU)
Backbone (GT)

Dataset

MS COCO

mAP

APall

5% 10% 20% 5% 10% 20%

OpenImage

mAP APall

39.14

45.30

61.82 83.82
54.94 56.34 59.03 56.86 58.36 61.26 61.53 85.88
55.10 56.77 58.72 57.53 59.33 61.18 65.66 89.57
49.78 50.13 50.29 45.99 46.03 46.16 61.90 84.80
46.57 49.83 51.83 47.63 50.63 52.64 62.36 87.68
46.42 50.15 52.14 46.47 50.59 52.76 62.38 87.67
58.28 59.51 60.55 59.86 61.12 62.34 69.02 94.08
57.95 59.19 60.11 60.03 61.39 62.33
58.16 59.29 60.19 60.19 61.54 62.44

‚Äì
‚Äì
‚Äì

‚Äì
‚Äì
‚Äì

65.16

68.15

Table 2. Multi-label classiÔ¨Åcation performance (in %) by the proposed approach and several baseline methods on the MS COCO and
OpenImage datasets. We choose 5%, 10% and 20% clean labels in MS COCO and all clean labels in training set of OpenImage as the
clean set, respectively. The best results except for the results using 100% clean labels, denoted as Backbone (GT), are highlighted in bold.

Backbone (GT): A backbone network is trained for
multi-label classiÔ¨Åcation using all
the clean labels in
dataset. This can be viewed as an upper bound of all meth-
ods which use clean labels. It should be noted that the Back-
bone (GT) is only trained on MS COCO since the clean la-
bels of whole OpenImage dataset are missing.

Backbone (Noisy-FT-W): Fine-tune the whole network
of Backbone (Noisy) with clean labels in the clean set. This
method directly uses clean labels to train a large network
which is prone to overÔ¨Åt when clean labels are few.

Backbone (Noisy-FT-M): Fine-tune the last layer of
Backbone (Noisy) with mixed labels in the clean set. The
mixed labels consist of both clean labels in clean set and
noisy labels in noisy set (in a ratio of 1 : 9).

Backbone (Noisy-FT-L): Fine-tune the last layer of
Backbone (Noisy) with clean labels in the clean set. This
method relieves the problem of overÔ¨Åtting by reducing pa-
rameters in training.

The results on MS COCO and OpenImage are reported
in Table 4.4 in terms of mAP and APall. We can see that on
MS COCO, all of the weakly supervised methods can sig-
niÔ¨Åcantly improve the performance compared to the base-
line method - Backbone (Noisy), even using only 5% clean
labels. This shows the positive inÔ¨Çuence of clean labels on
noisy label learning, and this inÔ¨Çuence grows with the in-
crease of clean label quantity. However, when extremely
few clean labels are available (e.g., 5%), the improvement
of model performance becomes more difÔ¨Åcult. Compared
to other methods, the proposed method shows the least per-
formance decrease (2.3% by our method vs. 3.6% by Back-
bone (Noisy-FT-L) in terms of mAP) from using 20% to 5%
clean labels while keeps the best performance.

Similar to MS COCO, we also conducted experiments
over different percent of clean labels for the training set
on OpenImage. For OpenImage dataset, the size of whole
clean set in training is about 40K. We then used several sub-

Metric

mAP
APall

Percent of clean labels

10% 20% 40% 60% 80% 100%
69.02
65.08
91.08
94.08

68.61
93.86

67.97
93.65

65.98
92.18

67.20
93.13

Table 3. Performance of image classiÔ¨Åcation on OpenImage (in
%) by the proposed approach using different percent of clean la-
bels for the training set.

sets of the clean set to train the model, with ratio of 10%,
20%, 40%, 60%, and 80%, respectively. The results are
given in Table 3. We can see that the proposed method can
keep the best classiÔ¨Åcation performance even the clean set
size is reduced to 20%. It concurs with the results on M-
S COCO, which achieves similar performance with Back-
bone (Noisy-FT-W) by using only half data (59.51% by our
method using 10% clean labels vs. 59.03% by Backbone
(Noisy-FT-W) using 20% clean labels in terms of mAP).
This can be encouraging and has practical signiÔ¨Åcance in
real scenarios since image annotation is usually an expen-
sive and time-consuming work, which is more practicable
to annotate 8K images rather than 40K images.

The results on MS COCO and OpenImage datasets
demonstrate the effectiveness of our model in leveraging
massive noisy labeled data with a small set of clean labels
to perform weakly supervised learning. The proposed ap-
proach achieves 3.1% (on MS COCO by using 5% clean
labels) and 3.3% (on OpenImage) higher performance than
the best of the baseline methods in terms of mAP. We give
some examples of the classiÔ¨Åcation results in Fig. 3. The
proposed method performs well in many hard cases that the
baseline methods cannot work well. It should be noted that
we only train the clean net and the residual net by Ô¨Åxing the
backbone network, and it is possible to have better results
if the entire network is trained. The possible reasons why
our method performs better than the state-of-the-art method

11522

Data

Pretrain top ‚àí 1
# Method
ImageNet 68.94
1 ResNet50 (Noisy)
ImageNet 75.19
2 ResNet50 (Clean)
3 CleanNet-wsof t [14]
ImageNet 74.69
79.90
4 Fine-tune
ImageNet 69.84
5 Forward [23]
80.38
6 Fine-tune
7 Proposed (sigmoid) Noisy set, Clean set ImageNet 79.93

Noisy set
Clean set
Noisy set
Clean set
Noisy set
Clean set

#3

#5

Table 4. Single-label classiÔ¨Åcation performance (in %) by the pro-
posed approach and several state-of-the-art methods on the Cloth-
ing1M dataset. The best results are highlighted in bold.

in terms of both mAP and APall. However, we Ô¨Ånd that
the convergence speeds of the three functions are different.
We also report the changes of mAP over iterations on MS
COCO dataset by using 5% clean labels. As shown in Fig.
4, the sigmoid function has the slowest convergence speed
among all three activate functions under the same learning
rate (10‚àí5). This is the reason why we use a higher learning
rate for the sigmoid function in our experiment.

4.5. Results for Single label Image ClassiÔ¨Åcation

We perform single-label image classiÔ¨Åcation on Cloth-
ing1M to evaluate the performance of the proposed ap-
proach and provide comparisons with the state-of-the-art
methods. Two important baselines we used are CleanNet-
wsof t [14] and Forward [23]. These methods are designed
for learning from the data with only noisy labels. Thus, to
utilize the data with clean labels, they need to Ô¨Åne-tune the
model, which denoted by Fine-tune in Table 4. Besides the
state-of-the-art methods, we also provide two other impor-
tant traditional baselines, ResNet50 (Noisy) and ResNet50
(Clean), which trains a backbone network using all the data
with noisy labels or clean labels in the dataset.

The results are reported in Table 4 in terms of top-1 ac-
curacy. We can see that the proposed method has compa-
rable accuracy with other state-of-the-art methods (79.93%
by our method vs. 80.38% by Forward [23] and 79.90% by
CleanNet-wsof t [14]) on the Clothing1M dataset. Both For-
ward [23] and the proposed method learn a mapping from
clean label space to noisy label space. Compared with the
proposed method, Forward [23] introduced extra informa-
tion, which used the paired noisy-clean labels to estimate
the label confusion matrix. This may be the reason why the
performance of [23] is slightly higher than us. However, in
real applications, paired labels are not available sometimes,
e.g., only 25K in 50K images in the training set of Cloth-
ing1M dataset have both clean and noisy labels. Thus the
requirement on paired labels in Forward [23] may also limit
its usage. For the state-of-the-art method [14], although we
achieve very similar results to it, the proposed method does
not need to generate the reference set which sometimes can
be very time-consuming.

11523

Figure 3. Examples of multi-label image classiÔ¨Åcation by the pro-
posed method and the baseline methods on the test set of the Open-
Image and MS COCO datasets. We provide the top-5 most con-
Ô¨Ådent predictions by Backbone (Noisy), Backbone (Noisy-FT-L)
and the proposed method, denoted as Baseline1, Baseline2 and
Proposed, respectively. We choose 5% clean labels as the clean
set of MS COCO.

Figure 4. The mAP of image classiÔ¨Åcation on MS COCO by
the proposed approach using different activate functions (sigmoid,
tanh and ReLU) and 5% clean labels.

by Veit et al. [30] are: i) we use a non-linear transforma-
tion to learn the mapping from image feature space to label
space while a linear transformation was used in [30]; ii) our
approach can make use of all the noisy data of the whole
dataset during network training, while [30] only used the
noisy labels of the images in the clean set.

We also report the performance using different activate
functions, i.e., sigmoid, tanh and ReLU, in order to get com-
prehensive understanding of the proposed method. The re-
sults on MS COCO dataset using three different activation
functions are given in Table 4.4. We can see that the per-
formance difference between three activate functions is mi-
nor, which is less than 0.5% from 5% to 20% clean labels

Baseline1carnivorananimalpetnosedogrugby unionrugby footballSuperset of top-5 predictionsImage from test set of OpenImagedatasetillustration drawingsketch  drizzle monochrome cartoon Baseline2Proposedfood cuisine  dishsalad  vegetableproduce recreationbroccolidining tablebowlknifeapplespoon hot dogpizzaBaseline1Baseline2ProposedSuperset of top-5predictionsumbrellabenchcarvasebowlchairdining tablebicyclecartraffic lightbusbicyclemotorcycletruckbackpackdogImage from test set of MS COCO dataset020000400006000080000Iteration45505560mAPsigmoidtanhReLUDataset OpenImage Clothing1M

Method
mAP APall
61.82 83.82
Backbone (Noisy)
training h alone
64.06 81.64
training g alone
67.34 93.73
training g, h jointly 69.02 94.08

top ‚àí 1
68.94
67.92
75.13
79.93

Table 5. InÔ¨Çuence of different training strategies to the image clas-
siÔ¨Åcation accuracy (in %). We use sigmoid as the activate function
for both OpenImage and Clothing1M datasets.

than Backbone (Noisy) since there is no explicit difference
between the clean net and the residual net. When we in-
troduce the data with clean labels to train classiÔ¨Åer g, the
different roles of the two nets can be recognized. Compared
to training g alone, training g, h jointly achieves 1.7% im-
provement on OpenImage in terms of mAP, and 4.8% im-
provement on Clothing1M in terms of top-1 accuracy. The
results suggest that the reliable information identiÔ¨Åed by
the residual net from massive noisy labeled data can im-
prove the performance of classiÔ¨Åer g in both single-label
and multi-label image classiÔ¨Åcation tasks.

5. Conclusion

While weakly supervised image classiÔ¨Åcation utilizing
massive noisy labeled data is valuable for practical appli-
cations where a large clean dataset is not available, it is
challenging because of the difÔ¨Åculty in exploiting the un-
derline semantic information from noisy data. We address
these issues by proposing a novel end-to-end trainable ap-
proach for weakly supervised learning that does not require
assumptions about the label type. The proposed approach
consists of a clean net and a residual net, which work in a
multi-task way, and are responsible for learning a mapping
from feature space to clean label space and a mapping from
feature space to the residual between clean labels and noisy
labels, respectively. As a result, the residual net can serve as
a regularization term to reduce the risk of overÔ¨Åtting of the
clean net. Extensive evaluations using both multi-label and
single-label image classiÔ¨Åcation tasks on the MS COCO,
OpenImage, and Clothing1M datasets show that the pro-
posed approach achieves promising results compared with
state-of-the-art, and has good generalization ability.

Acknowledgment

This research was supported in part by the National Key
R&D Program of China (grant 2017YFA0700800), Natural
Science Foundation of China (grants 61672496, 61650202,
and 61772500), and External Cooperation Program of Chi-
nese Academy of Sciences (CAS) (grant GJHZ1843).

11524

Figure 5. Examples of single-label image classiÔ¨Åcation generated
by the proposed method on Clothing1M. We show the top-3 pre-
dictions by the classiÔ¨Åer g and compare it with the corresponding
predictions of the classiÔ¨Åer h. The green and red labels denote the
clean and the noisy label, respectively. We normalize the predic-
tions by both classiÔ¨Åers for easy comparisons.

Compared to the state-of-the-art methods [23, 14], which
are restricted to single-label image classiÔ¨Åcation, the merit
of the proposed method is that it can be applied to multi-
label image classiÔ¨Åcation. The proposed method does not
have the single-label noise assumption, and performs well
on the multi-label dataset as the experiments showed previ-
ously. It suggests that our method generalizes well in both
single-label and multi-label image classiÔ¨Åcation scenarios.
Another merit of the proposed method is that it can use a
1-step training scheme while Forward [23] and CleanNet-
wsof t [14] need to Ô¨Årst train the base model on the data
with noisy labels and then do the Ô¨Åne-tuning on data with
clean labels. The proposed method uses the entire data to
train the whole network for only one time, which simpliÔ¨Åes
the training process while achieves high accuracy. Fig. 5
shows the examples of single-label image classiÔ¨Åcation by
the proposed method on Clothing1M. From the residual be-
tween the prediction of g and h, we can see that the residual
net is helpful for modeling the unreliable part in the noisy
data, which makes g and h better Ô¨Åt the clean labels and
noisy labels, respectively. However, if the images are too d-
ifÔ¨Åcult to classify, they may also lead to wrong predictions.

4.6. InÔ¨Çuence of Residual Net

To show the inÔ¨Çuence of the residual net in the whole
network, we provide ablation experiments to analyze the
performance of classiÔ¨Åers g and h. We provide two vari-
ants of our model in addition to proposed method (training
g, h jointly): i) training h alone (i.e., Œ± = 0); ii) training g
alone (i.e., only using clean labels to train the model). As
shown in Table 5, training h alone does not perform better

sweaterknitwearhoodiejacketwindbreakersuitt-shirtknitwearsweater98%1.5%0.02%78%20%0.7%15%69%0.6%58%39%1.4%94%74%3%23%1.6%0.1%Imagetop-3 predictionsprediction of gprediction of hReferences

[1] E. Beigman and B. B. Klebanov. Learning with annotation

noise. In Proc. ACL, pages 280‚Äì287, 2009.

[2] C. E. Brodley and M. A. Friedl.

Identifying mislabeled
Journal of ArtiÔ¨Åcial Intelligence Research,

training data.
11(1):131‚Äì167, 2011.

[3] X. Chen and A. Gupta. Webly supervised learning of convo-
lutional networks. In Proc. IEEE ICCV, pages 1431‚Äì1439,
2015.

[4] J. Deng, W. Dong, R. Socher, L. Li, K. Li, and F. Li. Im-
agenet: A large-scale hierarchical image database. In Proc.
IEEE CVPR, pages 248‚Äì255, 2009.

[5] B. Fr¬¥enay and M. Verleysen. ClassiÔ¨Åcation in the presence of
label noise: a survey. IEEE Transactions on Neural Networks
& Learning Systems, 25(5):845‚Äì869, 2014.

[6] A. Ghosh, H. Kumar, and P. S. Sastry. Robust loss functions
under label noise for deep neural networks. In Proc. AAAI,
2017.

[7] H. Han, A. K. Jain, F. Wang, S. Shan, and X. Chen. Hetero-
geneous face attribute estimation: A deep multi-task learning
approach. IEEE Transactions on Pattern Analysis and Ma-
chine Intelligence (T-PAMI), 40(11):2597‚Äì2609, Nov. 2018.
[8] H. Han, C. Otto, X. Liu, and A. K. Jain. Demographic esti-
mation from face images: Human vs. machine performance.
IEEE Transactions on Pattern Analysis and Machine Intelli-
gence (T-PAMI), 37(6):1148‚Äì1161, Jun. 2015.

[9] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning
for image recognition. In Proc. IEEE CVPR, pages 770‚Äì778,
2016.

[10] M. Hu, H. Han, S. Shan, and X. Chen. Multi-label learning
from noisy labels with non-linear feature transformation. In
Proc. ACCV, 2018.

[11] N. Inoue, E. Simoserra, T. Yamasaki, and H. Ishikawa.
Multi-label fashion image classiÔ¨Åcation with minimal human
supervision. In Proc. IEEE ICCV Workshops, pages 2261‚Äì
2267, 2017.

[12] D. Kingma and J. Ba. Adam: A method for stochastic opti-

mization. arXiv:1412.6980, 2014.

[13] I. Krasin, T. Duerig, N. Alldrin, A. Veit, S. Abu-El-Haija, S.
Belongie, D. Cai, Z. Feng, V. Ferrari, V. Gomes, A. Gupta,
D. Narayanan, C. Sun, G. Chechik, and K. Murphy. Openim-
ages: A public dataset for large-scale multi-label and multi-
class image classiÔ¨Åcation. arXiv:1701.01619, 2016.

[14] K. H. Lee, X. He, L. Zhang, and L. Yang. CleanNet: Trans-
fer learning for scalable image classiÔ¨Åer training with label
noise. In Proc. IEEE CVPR, 2018.

[15] Y. Li, J. Yang, Y. Song, L. Cao, J. Luo, and L.J. Li. Learning
In Proc. IEEE ICCV.,

from noisy labels with distillation.
pages 1928‚Äì1936, 2017.

[16] T. Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D.
Ramanan, P. Doll¬¥ar, and C. L. Zitnick. Microsoft COCO:
common objects in context. In Proc. ECCV, pages 740‚Äì755,
2014.

[17] T. Liu and D. Tao. ClassiÔ¨Åcation with noisy labels by impor-
tance reweighting. IEEE Trans. Pattern Anal. Mach. Intell,
38:447‚Äì461, 2016.

[18] W. Liu, G. Hua, and J. R. Smith. Unsupervised one-class
learning for automatic outlier removal. In Proc. IEEE CVPR,
pages 3826‚Äì3833, 2014.

[19] N. Manwani and P. S. Sastry. Noise tolerance under risk min-
imization. IEEE Transactions on Cybernetics, 43(3):1146‚Äì
1151, 2013.

[20] I. Misra, C. L. Zitnick, M. Mitchell, and R. Girshick. See-
ing through the human reporting bias: Visual classiÔ¨Åers from
noisy human-centric labels.
In Proc. IEEE CVPR, pages
2930‚Äì2939, 2016.

[21] N. Natarajan, I. S. Dhillon, P. Ravikumar, and A. Tewari.
Learning with noisy labels. In Proc. NIPS, pages 1196‚Äì1204,
2013.

[22] L. Niu, Q. Tang, A. Veeraraghavan, and A. Sabharwal.
Learning from noisy web data with category-level supervi-
sion. In Proc. IEEE CVPR, 2018.

[23] G. Patrini, A. Rozza, A. K. Menon, R. Nock, and L. Qu.
Making deep neural networks robust to label noise: A loss
correction approach.
In Proc. IEEE CVPR, pages 2233‚Äì
2241, July. 2017.

[24] S. Reed, H. Lee, D. Anguelov, C. Szegedy, D. Erhan, and A.
Rabinovich. Training deep neural networks on noisy labels
with bootstrapping. arXiv:1412.6596, 2014.

[25] D. Rolnick, A. Veit, S. Belongie, and N. Shavit. Deep learn-
ing is robust to massive label noise. arXiv:1705.10694, 2017.
[26] S. Sukhbaatar, J. Bruna, M. Paluri, L. Bourdev, and R. Fer-
gus. Training convolutional networks with noisy labels. In
Proc. ICLR Workshops., 2015.

[27] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna.
Rethinking the inception architecture for computer vision. In
Proc. IEEE CVPR, pages 2818‚Äì2826, 2016.

[28] D. Tanaka, D. Ikami, T. Yamasaki, and K. Aizawa. Joint
In

optimization framework for learning with noisy labels.
Proc. IEEE CVPR, 2018.

[29] T. Tieleman and G. Hinton. Lecture 6.5-rmsprop: Divide
the gradient by a running average of its recent magnitude.
COURSERA: Neural Networks for Machine Learning, 4(2),
2012.

[30] A. Veit, N. Alldrin, G. Chechik, I. Krasin, A. Gupta, and S.
Belongie. Learning from noisy large-scale datasets with min-
imal supervision. In Proc. IEEE CVPR, pages 6575‚Äì6583,
2017.

[31] F. Wang, H. Han, S. Shan, and X. Chen. Deep multi-task
learning for joint prediction of heterogeneous face attributes.
In Proc. 12th IEEE International Conference on Automatic
Face and Gesture Recognition (FG), pages 173‚Äì179, 2017.

[32] Y. Wang, W. Liu, X. Ma, J. Bailey, H. Zha, L. Song, and S. T.
Xia. Iterative learning with open-set noisy labels. In Proc.
IEEE CVPR, 2018.

[33] B. Wu, F. Jia, W. Liu, B. Ghanem, and S. Lyu. Multi-label
learning with missing labels using mixed dependency graph-
s.
International Journal of Computer Vision, 126(8):875‚Äì
896, 2018.

[34] T. Xiao, T. Xia, Y. Yang, C. Huang, and X. Wang. Learning
from massive noisy labeled data for image classiÔ¨Åcation. In
Proc. IEEE CVPR, pages 2691‚Äì2699, 2015.

11525

